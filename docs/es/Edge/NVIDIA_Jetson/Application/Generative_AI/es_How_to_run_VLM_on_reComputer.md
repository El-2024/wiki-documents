---
description: Esta wiki proporciona un tutorial sobre c√≥mo ejecutar VLM en reComputer Jetson.
title: C√≥mo Ejecutar VLM en reComputer
keywords:
- reComputer
- VLM
image: https://files.seeedstudio.com/wiki/wiki-platform/S-tempor.png
slug: /es/run_vlm_on_recomputer
last_update:
  date: 7/24/2024
  author: ZhuYaoHui
---

# C√≥mo Ejecutar VLM en reComputer con Jetson Platform Services

## Introducci√≥n

Los modelos de lenguaje visual (VLMs) son modelos multimodales que soportan im√°genes, video y texto y utilizan una combinaci√≥n de modelos de lenguaje grandes y transformadores de visi√≥n. Bas√°ndose en esta capacidad, son capaces de soportar prompts de texto para consultar videos e im√°genes, habilitando as√≠ capacidades como chatear con el video y definir alertas basadas en lenguaje natural. El [servicio de IA VLM](https://docs.nvidia.com/jetson/jps/inference-services/vlm.html), permite el despliegue r√°pido de VLMs con Jetson Platform Services para aplicaciones de an√°lisis de video. El servicio VLM expone endpoints de API REST para configurar la entrada de flujo de video, establecer alertas y hacer preguntas en lenguaje natural sobre el flujo de video de entrada.

Esta wiki proporciona un tutorial sobre c√≥mo ejecutar VLM en [reComputer J4012 Jetson Orin NX](https://www.seeedstudio.com/reComputer-J4012-p-5586.html).

<div align="center">
    <img width={900}
     src="https://files.seeedstudio.com/wiki/reComputer/Application/vlm/vlmgif.gif" />
</div>

## Requisitos

Antes de proceder con el proceso de configuraci√≥n, aseg√∫rese de que su sistema cumple con los siguientes prerrequisitos:

<div align="center">
    <img width={800}
     src="https://files.seeedstudio.com/wiki/reComputer/Application/reComputer_J4012.png" />
</div>

<div class="get_one_now_container" style={{textAlign: 'center'}}>
    <a class="get_one_now_item" href="https://files.seeedstudio.com/wiki/reComputer/Application/reComputer_J4012.png" target="_blank" rel="noopener noreferrer">
      <strong><span><font color={'FFFFFF'} size={"4"}> Obtener Uno Ahora üñ±Ô∏è</font></span></strong>
    </a>
</div>

- Un reComputer J4012 Orin NX 16G ejecutando Ubuntu `22.04` o `posterior`.
- Versi√≥n del Driver: `535.113.01`, Jetpack `6.0` y Versi√≥n CUDA: `12.2`.
- Aseg√∫rese de que JetPack y los paquetes de servicios Jetson relacionados est√©n instalados.

  ```bash
  sudo apt-get install nvidia-jetpack
  sudo apt install nvidia-jetson-services
  ```

- C√°maras IP o videos locales pueden ser transmitidos v√≠a RTSP. (Recomendamos usar nuestro [tutorial de NVStreamer](/getting_started_with_nvstreamer) proporcionado para transmisi√≥n RTSP.)

## Comenzando

**Paso 1**: Descargue el paquete de aplicaci√≥n **`vlm-1.1.0.tar.gz`** desde NGC a su Jetson usando este enlace: [NGC Reference Workflow and Resources](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/jps/resources/reference-workflow-and-resources). Necesitar√° ingresar sus credenciales NGC. En la p√°gina, use una de las opciones disponibles en el men√∫ **`Download`** (esquina superior derecha):

```bash
tar -xvf vlm-1.1.0.tar.gz
cd ~/vlm/example_1
```

**Paso 2**: El servicio de IA VLM utilizar√° los servicios `jetson-ingress` y `jetson-monitoring`. Necesita configurar estos dos servicios para integrarlos con el servicio de IA VLM. Copie la configuraci√≥n predeterminada proporcionada al directorio de configuraci√≥n del servicio correspondiente:

```bash
sudo cp config/vlm-nginx.conf /opt/nvidia/jetson/services/ingress/config
sudo cp config/prometheus.yml /opt/nvidia/jetson/services/monitoring/config/prometheus.yml
sudo cp config/rules.yml /opt/nvidia/jetson/services/monitoring/config/rules.yml
```

**Paso 3**: Ejecute los servicios b√°sicos:

```bash
sudo systemctl start jetson-ingress
sudo systemctl start jetson-monitoring
sudo systemctl start jetson-sys-monitoring
sudo systemctl start jetson-gpu-monitoring
sudo systemctl start jetson-redis
sudo systemctl start jetson-vst
```

**Paso 4**: Al iniciar el servicio VLM por primera vez, autom√°ticamente descargar√° y cuantizar√° el VLM. Este proceso puede tomar alg√∫n tiempo. Si est√° desplegando en Orin NX16, podr√≠a necesitar montar m√°s espacio SWAP porque el proceso de cuantizaci√≥n puede consumir una gran cantidad de memoria. Ejecute los siguientes comandos para montar m√°s espacio swap:

```bash
sudo fallocate -l 10G /data/10GB.swap
sudo mkswap /data/10GB.swap
sudo swapon /data/10GB.swap
```

**Paso 5**: Inicie el servicio de IA VLM:

```bash
cd ~/vlm/example_1
sudo docker compose up -d
```

Para verificar si todos los contenedores requeridos han iniciado, puede ejecutar el siguiente comando:

```bash
sudo docker ps
```

<div align="center">
    <img width={1000}
     src="https://files.seeedstudio.com/wiki/reComputer/Application/vlm/vlmfig2.png" />
</div>

## Agregar la entrada de flujo RTSP

Primero puede agregar un flujo RTSP para que el modelo VLM lo use con el siguiente comando curl. Se recomienda usar el [tutorial de NVStreamer](/getting_started_with_nvstreamer) para transmisi√≥n.

- **Paso 1**: Reemplace `0.0.0.0` con la IP de su Jetson y el enlace `liveStreamUrl` con su enlace RTSP, luego ingrese el siguiente comando en la terminal:

    ```bash
    curl --location 'http://0.0.0.0:5010/api/v1/live-stream' \
    --header 'Content-Type: application/json' \
    --data '{
    "liveStreamUrl": "rtsp://0.0.0.0:31554/nvstream/root/store/nvstreamer_videos/car.mp4"
    }'
    ```

    Nota: Adem√°s del comando curl, tambi√©n puede probar directamente la API REST a trav√©s de la p√°gina de documentaci√≥n de la API, que est√° disponible en `http://0.0.0.0:5010/docs` cuando el servicio de detecci√≥n zero-shot est√° iniciado.

- **Paso 2**: Despu√©s de ejecutar el primer paso, se devolver√° un ID. Necesita registrar este ID para usarlo en pasos posteriores:

    ```bash
    {"id": "a782e200-eb48-4d17-a1b9-5ac0696217f7"}
    ```

    Tambi√©n puede obtener el ID m√°s tarde usando el siguiente comando:

    ```bash
    curl --location 'http://0.0.0.0:5010/api/v1/live-stream'
    ```

    Para eliminar un flujo por su ID, puede usar el siguiente comando:

    ```bash
    curl --location --request DELETE 'http://0.0.0.0:5010/api/v1/live-stream/{id}'
    ```

## Configurar Alertas

Las alertas son preguntas que el VLM evaluar√° continuamente en la entrada del flujo en vivo. Para cada conjunto de reglas de alerta, el VLM intentar√° decidir si es Verdadero o Falso bas√°ndose en el frame m√°s reciente del flujo en vivo. Estos estados Verdadero y Falso seg√∫n lo determinado por el VLM, se env√≠an a un websocket y al servicio de monitoreo jetson.

Al configurar alertas, la regla de alerta debe formularse como una pregunta de s√≠/no. Como "¬øHay fuego?" o "¬øHay humo?". El cuerpo de la solicitud tambi√©n debe tener el campo "id" que corresponde al ID del flujo que se devolvi√≥ cuando se agreg√≥ el flujo RTSP.

Por defecto, el servicio VLM soporta hasta 10 reglas de alerta. Esto puede incrementarse ajustando los archivos de configuraci√≥n.

**Paso 1**: Reemplace `0.0.0.0` con la direcci√≥n IP de su reComputer, modifique `alerts` para incluir los objetos para los que necesita alertas, use el `id` devuelto en el paso anterior. Despu√©s de completar el comando, ingrese lo siguiente en la terminal:

``` bash
curl --location 'http://0.0.0.0:5010/api/v1/alerts' \
--header 'Content-Type: application/json' \
--data '{
    "alerts": ["is there a fire?", "is there smoke?"],
    "id": "a782e200-eb48-4d17-a1b9-5ac0696217f7"
}'
```

## Ver Resultado del Flujo RTSP

La salida de detecci√≥n ser√° transmitida a trav√©s de `rtsp://reComputer_ip:5011/out`. Proporcionamos un script de Python para visualizar la salida del flujo de video, Necesita instalar la librer√≠a opencv-python con anticipaci√≥n y luego ejecutar el siguiente script de Python:

- **Paso 1:** Instale la librer√≠a opencv-python:

    ```bash
    pip install opencv-python
    ```

- **Paso 2:** Ejecute el siguiente script de Python:

    ```python
    import cv2
    rtsp_url = "rtsp://reComputer_ip:5011/out"
    cap = cv2.VideoCapture(rtsp_url)
    if not cap.isOpened():
        print("Cannot open RTSP stream")
        exit()
    while True:
        ret, frame = cap.read()
        if not ret:
            print("Failed to retrieve frame")
            break
        cv2.imshow('RTSP Stream', frame)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
    cap.release()
    cv2.destroyAllWindows()
    ```

## Apagar

Para detener el servicio de detecci√≥n zero-shot, ejecute el siguiente comando en el mismo directorio donde se encuentra el archivo `compose.yaml`:

```bash
sudo docker compose down
```

## M√°s Detalles

Modelos de Lenguaje Visual (VLM) con Jetson Platform Services: https://docs.nvidia.com/jetson/jps/inference-services/vlm.html

## Soporte T√©cnico y Discusi√≥n de Productos

¬°Gracias por elegir nuestros productos! Estamos aqu√≠ para brindarle diferentes tipos de soporte para asegurar que su experiencia con nuestros productos sea lo m√°s fluida posible. Ofrecemos varios canales de comunicaci√≥n para atender diferentes preferencias y necesidades.

<div class="button_tech_support_container">
<a href="https://forum.seeedstudio.com/" class="button_forum"></a>
<a href="https://www.seeedstudio.com/contacts" class="button_email"></a>
</div>

<div class="button_tech_support_container">
<a href="https://discord.gg/eWkprNDMU7" class="button_discord"></a>
<a href="https://github.com/Seeed-Studio/wiki-documents/discussions/69" class="button_discussion"></a>
</div>
