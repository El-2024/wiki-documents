---
description: Este wiki proporciona el tutorial de ensamblaje y depuraci√≥n para el SO ARM100 y realiza la recopilaci√≥n de datos y entrenamiento dentro de la √∫ltima versi√≥n del framework Lerobot.
title: SoArm en Lerobot
keywords:
- Lerobot
- Huggingface
- Arm
- Robotics
image: https://files.seeedstudio.com/wiki/robotics/projects/lerobot/Arm_kit.webp
slug: /es/lerobot_so100m_new
last_update:
  date: 8/20/2025
  author: LiShanghang
---

# C√≥mo usar el brazo rob√≥tico SO-ARM100 y SO-ARM101 en la √∫ltima versi√≥n de Lerobot

:::tip
El mantenimiento de este tutorial ha sido actualizado a la √∫ltima versi√≥n de [lerobot](https://huggingface.co/docs/lerobot/index), si deseas consultar el tutorial de la versi√≥n anterior, por favor haz clic [aqu√≠](https://wiki.seeedstudio.com/es/lerobot_so100m/).
:::

## Introducci√≥n

El [SO-10xARM](https://github.com/TheRobotStudio/SO-ARM100) es un proyecto de brazo rob√≥tico completamente de c√≥digo abierto lanzado por [TheRobotStudio](https://www.therobotstudio.com/). Incluye el brazo seguidor y el brazo rob√≥tico l√≠der, y tambi√©n proporciona archivos detallados de impresi√≥n 3D y gu√≠as de operaci√≥n. [LeRobot](https://github.com/huggingface/lerobot/tree/main) se compromete a proporcionar modelos, conjuntos de datos y herramientas para rob√≥tica del mundo real en PyTorch. Su objetivo es reducir la barrera de entrada de la rob√≥tica, permitiendo que todos contribuyan y se beneficien del intercambio de conjuntos de datos y modelos preentrenados. LeRobot integra metodolog√≠as de vanguardia validadas para aplicaciones del mundo real, centr√°ndose en el aprendizaje por imitaci√≥n. Ha proporcionado un conjunto de modelos preentrenados, conjuntos de datos con demostraciones recopiladas por humanos y entornos de simulaci√≥n, permitiendo a los usuarios comenzar sin la necesidad de ensamblar robots. En las pr√≥ximas semanas, la intenci√≥n es aumentar el soporte para rob√≥tica del mundo real en los robots m√°s rentables y competentes actualmente accesibles.

<div class="video-container">
<iframe width="900" height="600" src="https://www.youtube.com/embed/sD34HnAkGNc?si=hqKd_sH5Oc9sdcwd" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
</div>

## Introducci√≥n del Proyecto

El kit de robot inteligente SO-ARM10x y reComputer Jetson AI combina perfectamente el control de brazo rob√≥tico de alta precisi√≥n con una potente plataforma de computaci√≥n AI, proporcionando una soluci√≥n integral de desarrollo de robots. Este kit est√° basado en la plataforma Jetson Orin o AGX Orin, combinado con el brazo rob√≥tico SO-ARM10x y el framework AI LeRobot, ofreciendo a los usuarios un sistema de robot inteligente aplicable a m√∫ltiples escenarios como educaci√≥n, investigaci√≥n y automatizaci√≥n industrial.
Este wiki proporciona el tutorial de ensamblaje y depuraci√≥n para el SO ARM10x y realiza la recopilaci√≥n de datos y entrenamiento dentro del framework Lerobot.

  <div align="center">
      <img width={800}
      src="https://files.seeedstudio.com/wiki/robotics/projects/lerobot/Arm_kit.png" />
  </div>

<div class="get_one_now_container" style={{textAlign: 'center'}}>
<a class="get_one_now_item" href="https://www.seeedstudio.com/SO-ARM100-Low-Cost-AI-Arm-Kit.html" target="_blank">
            <strong><span><font color={'FFFFFF'} size={"4"}> Obtener Uno Ahora üñ±Ô∏è</font></span></strong>
</a></div>

## Caracter√≠sticas Principales

1. **C√≥digo abierto y bajo costo**: Es una soluci√≥n de brazo rob√≥tico de c√≥digo abierto y bajo costo de [TheRobotStudio](https://github.com/TheRobotStudio/SO-ARM100)
2. **Integraci√≥n con LeRobot**: Dise√±ado para integraci√≥n con la [plataforma LeRobot](https://github.com/huggingface/lerobot)
3. **Abundantes recursos de aprendizaje**: Proporciona recursos de aprendizaje de c√≥digo abierto integrales como gu√≠as de ensamblaje y calibraci√≥n, y tutoriales para pruebas, recopilaci√≥n de datos, entrenamiento y despliegue para ayudar a los usuarios a comenzar r√°pidamente y desarrollar aplicaciones rob√≥ticas.
4. **Compatible con Nvidia**: Despliega este kit de brazo con reComputer Mini J4012 Orin NX 16 GB.
5. **Aplicaci√≥n Multi-Escenario**: Es aplicable a campos como educaci√≥n, investigaci√≥n cient√≠fica, producci√≥n automatizada y rob√≥tica, ayudando a los usuarios a lograr operaciones de robot eficientes y precisas en varias tareas complejas.

## NovedadesÔºö

- Optimizaci√≥n del cableado: Comparado con SO-ARM100, SO-ARM101 presenta un cableado mejorado que previene problemas de desconexi√≥n previamente vistos en la articulaci√≥n 3. El nuevo dise√±o de cableado tambi√©n ya no limita el rango de movimiento de las articulaciones.
- Diferentes relaciones de engranajes para el brazo l√≠der: El brazo l√≠der ahora usa motores con relaciones de engranajes optimizadas, mejorando el rendimiento y eliminando la necesidad de cajas de engranajes externas.
- Soporte de nueva funcionalidad: El brazo l√≠der ahora puede seguir al brazo seguidor en tiempo real, lo cual es crucial para la pr√≥xima pol√≠tica de aprendizaje, donde un humano puede intervenir y corregir las acciones del robot.

:::caution

Seeed Studio solo es responsable de la calidad del hardware en s√≠. Los tutoriales se actualizan estrictamente de acuerdo con la documentaci√≥n oficial. Si encuentras problemas de software o problemas de dependencias del entorno que no se pueden resolver, adem√°s de verificar la secci√≥n FAQ al final de este tutorial, por favor reporta el problema oportunamente a la [plataforma LeRobot](https://github.com/huggingface/lerobot) o al [canal Discord de LeRobot](https://discord.gg/8TnwDdjFGU).

:::

<div class="video-container">
<iframe width="900" height="600" src="https://www.youtube.com/embed/JrF_ymUvrqc?si=vslu5NNI-ZIzVXLc" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
</div>

## Especificaciones

<table>
  <thead>
    <tr>
      <th>Tipo</th>
      <th colSpan="2">SO-ARM100</th>
      <th colSpan="2">SO-ARM101</th>
    </tr>
    <tr>
      <th></th>
      <th><a href="https://www.seeedstudio.com/SO-ARM100-Low-Cost-AI-Arm-Kit.html" target="_blank">Kit de Brazo</a></th>
      <th><a href="https://www.seeedstudio.com/SO-ARM100-Low-Cost-AI-Arm-Kit-Pro-p-6343.html" target="_blank">Kit de Brazo Pro</a></th>
      <th><a href="https://www.seeedstudio.com/SO-ARM100-Low-Cost-AI-Arm-Kit.html" target="_blank">Kit de Brazo</a></th>
      <th><a href="https://www.seeedstudio.com/SO-ARM100-Low-Cost-AI-Arm-Kit-Pro-p-6343.html" target="_blank">Kit de Brazo Pro</a></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Brazo L√≠der</td>
      <td rowSpan="2">12x motores ST-3215- C001 (7.4V) con relaci√≥n de engranajes 1:345 para todas las articulaciones</td>
      <td rowSpan="2">12x motores ST-3215-C018/ST-3215-C047 (12V) con relaci√≥n de engranajes 1:345 para todas las articulaciones</td>
      <td colSpan="2">
        1x motor ST-3215- C001 (7.4V) con relaci√≥n de engranajes 1:345 solo para la articulaci√≥n 2<br />
        2x motores ST-3215-C044 (7.4V) con relaci√≥n de engranajes 1:191 para las articulaciones 1 y 3<br />
        3x motores ST-3215-C046 (7.4V) con relaci√≥n de engranajes 1:147 para las articulaciones 4, 5 y pinza (articulaci√≥n 6)
      </td>
    </tr>
    <tr>
      <td>Brazo Seguidor</td>
      <td colSpan="2">Igual que SO-ARM100</td>
    </tr>
    <tr>
      <td>Fuente de Alimentaci√≥n</td>
      <td>5.5 mm √ó 2.1 mm DC 5 V 4 A</td>
      <td>5.5 mm √ó 2.1 mm DC 12 V 2 A</td>
      <td>5.5 mm √ó 2.1 mm DC 5 V 4 A</td>
      <td>
        5.5 mm √ó 2.1 mm DC 12 V 2 A (Brazo Seguidor)<br />
        5.5 mm √ó 2.1 mm DC 5 V 4 A (Brazo L√≠der)
      </td>
    </tr>
    <tr>
      <td>Sensor de √Ångulo</td>
      <td colSpan="4">Codificador magn√©tico de 12 bits</td>
    </tr>
    <tr>
      <td>Temperatura de Operaci√≥n Recomendada</td>
      <td colSpan="4">0 ¬∞C a 40 ¬∞C</td>
    </tr>
    <tr>
      <td>Comunicaci√≥n</td>
      <td colSpan="4">UART</td>
    </tr>
    <tr>
      <td>M√©todo de Control</td>
      <td colSpan="4">PC</td>
    </tr>
  </tbody>
</table>

:::danger

Si compras la versi√≥n Arm Kit, ambas fuentes de alimentaci√≥n son de 5V. Si compras la versi√≥n Arm Kit Pro, por favor usa la fuente de alimentaci√≥n de 5V para la calibraci√≥n y cada paso del brazo rob√≥tico L√≠der, y la fuente de alimentaci√≥n de 12V para la calibraci√≥n y cada paso del brazo rob√≥tico Seguidor.

:::

## Lista de Materiales (BOM)

| Parte | Cantidad | Incluido|
|--|--|--|
|  Motores Servo | 12 | ‚úÖ |
| Placa de Control de Motor | 2 | ‚úÖ |
| Cable USB-C 2 piezas | 1 | ‚úÖ |
| Fuente de Alimentaci√≥n2 | 2 | ‚úÖ |
| Abrazadera de Mesa| 4 | ‚úÖ |
| Partes impresas en 3D del brazo | 1 | Opci√≥n |

## Entorno del Sistema Inicial

**Para Ubuntu x86:**

- Ubuntu 22.04  
- CUDA 12+  
- Python 3.10  
- Torch 2.6+  

**Para Jetson Orin:**

- Jetson JetPack 6.0 y 6.1, no soporta 6.1
- Python 3.10  
- Torch 2.3+

## Tabla de Contenidos

  [A. Gu√≠a de Impresi√≥n 3D](https://wiki.seeedstudio.com/es/lerobot_so100m_new/#install-lerobot)

  [B. Instalar LeRobot](https://wiki.seeedstudio.com/es/lerobot_so100m_new/#install-lerobot)

  [C. Configurar los motores](https://wiki.seeedstudio.com/es/lerobot_so100m_new/#configure-the-motors)

  [D. Ensamblaje](https://wiki.seeedstudio.com/es/lerobot_so100m_new/#assembly)

  [E. Calibrar](https://wiki.seeedstudio.com/es/lerobot_so100m_new/#calibrate)

  [F. Teleoperaci√≥n](https://wiki.seeedstudio.com/es/lerobot_so100m_new/#teleoperate)

  [G. Agregar c√°maras](https://wiki.seeedstudio.com/es/lerobot_so100m_new/#add-cameras)

  [H. Grabar el conjunto de datos](https://wiki.seeedstudio.com/es/lerobot_so100m_new/#record-the-dataset)

  [I. Visualizar el conjunto de datos](https://wiki.seeedstudio.com/es/lerobot_so100m_new/#visualize-the-dataset)

  [J. Reproducir un episodio](https://wiki.seeedstudio.com/es/lerobot_so100m_new/#replay-an-episode)

  [K. Entrenar una pol√≠tica](https://wiki.seeedstudio.com/es/lerobot_so100m_new/#train-a-policy)

  [L. Evaluar tu pol√≠tica](https://wiki.seeedstudio.com/es/lerobot_so100m_new/#evaluate-your-policy)

## Gu√≠a de Impresi√≥n 3D

:::caution
Siguiendo la actualizaci√≥n oficial de SO101, SO100 ya no ser√° compatible y los archivos fuente ser√°n eliminados seg√∫n lo oficial, pero los archivos fuente a√∫n se pueden encontrar en nuestro [Makerworld](https://makerworld.com/zh/models/908660). Sin embargo, para los usuarios que han comprado previamente SO100, los tutoriales y m√©todos de instalaci√≥n siguen siendo compatibles. La impresi√≥n de SO101 es completamente compatible con la instalaci√≥n del kit de motor de SO100.
:::

### Paso 1: Elegir una impresora

Los archivos STL proporcionados est√°n listos para imprimir en muchas impresoras FDM. A continuaci√≥n se muestran las configuraciones probadas y sugeridas aunque otras pueden funcionar.

- Material: PLA+
- Di√°metro de Boquilla y Precisi√≥n: di√°metro de boquilla de 0.4mm a altura de capa de 0.2mm o boquilla de 0.6mm a altura de capa de 0.4mm.
- Densidad de Relleno: 15%  

### Paso 2: Configurar la impresora
- Aseg√∫rese de que la impresora est√© calibrada y que el nivel de la cama est√© configurado correctamente usando las instrucciones espec√≠ficas de la impresora.
- Limpie la cama de impresi√≥n, asegur√°ndose de que est√© libre de polvo o grasa. Si limpia la cama con agua u otro l√≠quido, seque la cama.
- Si su impresora lo recomienda, use una barra de pegamento est√°ndar y aplique una capa delgada y uniforme de pegamento en el √°rea de impresi√≥n de la cama. Evite la acumulaci√≥n o aplicaci√≥n desigual.
- Cargue el filamento de la impresora usando las instrucciones espec√≠ficas de la impresora.
- Aseg√∫rese de que la configuraci√≥n de la impresora coincida con las sugeridas anteriormente (la mayor√≠a de las impresoras tienen m√∫ltiples configuraciones, as√≠ que elija las que m√°s se acerquen).
- Configure para soportes en todas partes pero ignore pendientes mayores a 45 grados respecto a la horizontal.
- No debe haber soportes en los agujeros de tornillos con ejes horizontales.

### Paso 3: Imprimir las piezas

Todas las piezas para el l√≠der o seguidor est√°n ya contenidas en un solo archivo para facilitar la impresi√≥n 3D, correctamente orientadas con z hacia arriba para minimizar los soportes.

- Para tama√±os de cama de impresora de 220mmx220mm (como la Ender), imprima estos archivos:
  - [Seguidor](https://github.com/TheRobotStudio/SO-ARM100/blob/main/STL/SO101/Follower/Ender_Follower_SO101.stl)
  - [L√≠der](https://github.com/TheRobotStudio/SO-ARM100/blob/main/STL/SO101/Leader/Ender_Leader_SO101.stl)

- Para tama√±os de cama de impresora de 205mm x 250mm (como la Prusa/Up):
  - [Seguidor](https://github.com/TheRobotStudio/SO-ARM100/blob/main/STL/SO101/Follower/Prusa_Follower_SO101.stl)
  - [L√≠der](https://github.com/TheRobotStudio/SO-ARM100/blob/main/STL/SO101/Leader/Prusa_Leader_SO101.stl)

## Instalar LeRobot

Los entornos como pytorch y torchvision necesitan ser instalados bas√°ndose en su CUDA.

1. Instalar Miniconda:
Para Jetson:

```bash
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh
chmod +x Miniconda3-latest-Linux-aarch64.sh
./Miniconda3-latest-Linux-aarch64.sh
source ~/.bashrc
```

O, Para X86 Ubuntu 22.04:

```bash
mkdir -p ~/miniconda3
cd miniconda3
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.sh
bash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3
rm ~/miniconda3/miniconda.sh
source ~/miniconda3/bin/activate
conda init --all
```

2. Crear y activar un entorno conda nuevo para lerobot

```bash
conda create -y -n lerobot python=3.10 && conda activate lerobot
```

3. Clonar Lerobot:

```bash
git clone https://github.com/Seeed-Projects/lerobot.git ~/lerobot
```

4. Al usar miniconda, instale ffmpeg en su entorno:

```bash
conda install ffmpeg -c conda-forge
```

:::tip
Esto generalmente instala ffmpeg 7.X para su plataforma compilado con el codificador libsvtav1. Si libsvtav1 no es compatible (verifique los codificadores compatibles con ffmpeg -encoders), puede:

- [En cualquier plataforma] Instalar expl√≠citamente ffmpeg 7.X usando:

```bash
conda install ffmpeg=7.1.1 -c conda-forge
```

- [Solo en Linux] Instalar las dependencias de compilaci√≥n de ffmpeg y compilar ffmpeg desde el c√≥digo fuente con libsvtav1, y aseg√∫rese de usar el binario ffmpeg correspondiente a su instalaci√≥n con which ffmpeg.

Si encuentra un error como este, tambi√©n puede usar este comando.

<div align="center">
    <img width={800}
    src="https://files.seeedstudio.com/wiki/robotics/projects/lerobot/lekiwi/No valid stream.png" />
</div>

:::

5. Instalar LeRobot con dependencias para los motores feetech:

```bash
cd ~/lerobot && pip install -e ".[feetech]"
```

Para dispositivos Jetson Jetpack 6.0+ (aseg√∫rese de instalar [Pytorch-gpu y Torchvision](https://github.com/Seeed-Projects/reComputer-Jetson-for-Beginners/blob/main/3-Basic-Tools-and-Getting-Started/3.3-Pytorch-and-Tensorflow/README.md#installing-pytorch-on-recomputer-nvidia-jetson) del paso 5 antes de ejecutar este paso):

```bash
conda install -y -c conda-forge "opencv>=4.10.0.84"  # Install OpenCV and other dependencies through conda, this step is only for Jetson Jetpack 6.0+
conda remove opencv   # Uninstall OpenCV 
pip3 install opencv-python==4.10.0.84  # Then install opencv-python via pip3
conda install -y -c conda-forge ffmpeg
conda uninstall numpy
pip3 install numpy==1.26.0  # This should match torchvision
```

6. Verificar Pytorch y Torchvision

Dado que instalar el entorno lerobot a trav√©s de pip desinstalar√° el Pytorch y Torchvision originales e instalar√° las versiones CPU de Pytorch y Torchvision, necesita realizar una verificaci√≥n en Python.

```python
import torch
print(torch.cuda.is_available())
```

Si el resultado impreso es False, necesita reinstalar Pytorch y Torchvision seg√∫n el [tutorial del sitio web oficial](https://pytorch.org/index.html).

Si est√° usando un dispositivo Jetson, instale Pytorch y Torchvision seg√∫n [este tutorial](https://github.com/Seeed-Projects/reComputer-Jetson-for-Beginners/blob/main/3-Basic-Tools-and-Getting-Started/3.3-Pytorch-and-Tensorflow/README.md#installing-pytorch-on-recomputer-nvidia-jetson).

## Configurar los motores

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

<Tabs>

<TabItem value="SO101" label="SO101">

El proceso de calibraci√≥n e inicializaci√≥n del servo para SO-ARM101 es el mismo que el de SO-ARM100 en t√©rminos tanto de m√©todo como de c√≥digo. Sin embargo, tenga en cuenta que las relaciones de engranajes para las primeras tres articulaciones del Brazo L√≠der SO-ARM101 difieren de las de SO-ARM100, por lo que es importante distinguir y calibrarlas cuidadosamente.

Para configurar los motores, designe un adaptador de servo de bus y 6 motores para su brazo l√≠der, y de manera similar el otro adaptador de servo de bus y 6 motores para el brazo seguidor. Es conveniente etiquetarlos y escribir en cada motor si es para el seguidor F o para el l√≠der L y su ID del 1 al 6. Usamos **F1‚ÄìF6** para representar las articulaciones 1 a 6 del **Brazo Seguidor**, y **L1‚ÄìL6** para representar las articulaciones 1 a 6 del **Brazo L√≠der**. Los detalles correspondientes del modelo de servo, asignaciones de articulaciones y relaci√≥n de engranajes son los siguientes:

| Modelo de Servo                        | Relaci√≥n de Engranajes | Articulaciones Correspondientes |
|----------------------------------------|------------|------------------------------|
| ST-3215-C044(7.4V)                     | 1:191      | L1                           |
| ST-3215-C001(7.4V)                     | 1:345      | L2                           |
| ST-3215-C044(7.4V)                     | 1:191      | L3                           |
| ST-3215-C046(7.4V)                     | 1:147      | L4‚ÄìL6                        |
| ST-3215-C001(7.4V) / C018(12V) / C047(12V) | 1:345      | F1‚ÄìF6                        |

:::danger
Ahora debe conectar la fuente de alimentaci√≥n de 5V o 12V al bus del motor. 5V para los motores STS3215 7.4V y 12V para los motores STS3215 12V. Tenga en cuenta que el brazo l√≠der siempre usa los motores de 7.4V, as√≠ que tenga cuidado de conectar la fuente de alimentaci√≥n correcta si tiene motores de 12V y 7.4V, ¬°de lo contrario podr√≠a quemar sus motores! Ahora, conecte el bus del motor a su computadora a trav√©s de USB. Tenga en cuenta que el USB no proporciona energ√≠a, y tanto la fuente de alimentaci√≥n como el USB deben estar conectados.
:::

<div align="center">
    <img width={800}
    src="https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/all_motos.png" />
</div>

***Los siguientes son los pasos de calibraci√≥n del c√≥digo, por favor calibre con el servo de cableado de referencia en la imagen de arriba***

Encontrar puertos USB asociados a sus brazos
Para encontrar los puertos correctos para cada brazo, ejecute el script de utilidad dos veces:

```bash
python -m lerobot.find_port
```

Salida de ejemplo:

```bash
Finding all available ports for the MotorBus.
['/dev/ttyACM0', '/dev/ttyACM1']
Remove the usb cable from your MotorsBus and press Enter when done.

[...Disconnect corresponding leader or follower arm and press Enter...]

The port of this MotorsBus is /dev/ttyACM1
Reconnect the USB cable.
```

:::tip
Recuerde quitar el usb, de lo contrario la interfaz no ser√° detectada.
:::

Salida de ejemplo al identificar el puerto del brazo l√≠der (por ejemplo, `/dev/tty.usbmodem575E0031751` en Mac, o posiblemente `/dev/ttyACM0` en Linux):

Salida de ejemplo al identificar el puerto del brazo seguidor (por ejemplo, `/dev/tty.usbmodem575E0032081`, o posiblemente `/dev/ttyACM1` en Linux):

Podr√≠a necesitar dar acceso a los puertos USB ejecutando:

```bash
sudo chmod 666 /dev/ttyACM0
sudo chmod 666 /dev/ttyACM1
```

**Configure sus motores**

:::danger
Por favor use una fuente de alimentaci√≥n de 5V para calibrar los motores L√≠der (ST-3215-C046, C044, 001).
:::

| **Calibraci√≥n Articulaci√≥n 6 Brazo L√≠der** | **Calibraci√≥n Articulaci√≥n 5 Brazo L√≠der** | **Calibraci√≥n Articulaci√≥n 4 Brazo L√≠der** | **Calibraci√≥n Articulaci√≥n 3 Brazo L√≠der** | **Calibraci√≥n Articulaci√≥n 2 Brazo L√≠der** | **Calibraci√≥n Articulaci√≥n 1 Brazo L√≠der** |
|:---------:|:---------:|:---------:|:---------:|:---------:|:---------:|
| ![fig1](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/cal_L6.jpg) | ![fig2](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/cal_L5.jpg) | ![fig3](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/cal_L4.jpg) |![fig4](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/cal_L3.jpg) |![fig5](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/cal_L2.jpg) |![fig6](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/cal_L1.jpg) |

:::danger
Si compra la versi√≥n Arm Kit (ST-3215-C001), use una fuente de alimentaci√≥n de 5V. Si compra la versi√≥n Arm Kit Pro, por favor use una fuente de alimentaci√≥n de 12V para calibrar el servo (ST-3215-C047/ST-3215-C018).
:::

| **Calibraci√≥n Articulaci√≥n 6 Brazo Seguidor** | **Calibraci√≥n Articulaci√≥n 5 Brazo Seguidor** | **Calibraci√≥n Articulaci√≥n 4 Brazo Seguidor** | **Calibraci√≥n Articulaci√≥n 3 Brazo Seguidor** | **Calibraci√≥n Articulaci√≥n 2 Brazo Seguidor** | **Calibraci√≥n Articulaci√≥n 1 Brazo Seguidor** |
|:---------:|:---------:|:---------:|:---------:|:---------:|:---------:|
| ![fig1](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/cal_F6.jpg) | ![fig2](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/cal_F5.jpg) | ![fig3](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/cal_F4.jpg) |![fig4](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/cal_F3.jpg) |![fig5](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/cal_F2.jpg) |![fig6](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/cal_F1.jpg) |
:::tip
Nuevamente, aseg√∫rese de que los IDs de las articulaciones del servo y las relaciones de engranajes correspondan estrictamente a las del SO-ARM101.
:::

Conecte el cable USB de su computadora y la fuente de alimentaci√≥n a la placa controladora del brazo seguidor. Luego, ejecute el siguiente comando.

```bash
python -m lerobot.setup_motors \
    --robot.type=so101_follower \
    --robot.port=/dev/ttyACM0  # <- paste here the port found at previous step
```

Deber√≠a ver la siguiente instrucci√≥n.

```bash
Connect the controller board to the 'gripper' motor only and press enter.
```

Como se indica, conecte el motor de la pinza. Aseg√∫rese de que sea el √∫nico motor conectado a la placa, y que el motor en s√≠ no est√© a√∫n conectado en cadena a ning√∫n otro motor. Al presionar [Enter], el script configurar√° autom√°ticamente el id y la velocidad de transmisi√≥n para ese motor.

Luego deber√≠a ver el siguiente mensaje:

```bash
'gripper' motor id set to 6
```

Seguido de la siguiente instrucci√≥n:

```bash
Connect the controller board to the 'wrist_roll' motor only and press enter.
```

Puede desconectar el cable de 3 pines de la placa controladora, pero puede dejarlo conectado al motor de la pinza en el otro extremo, ya que ya estar√° en el lugar correcto. Ahora, conecte otro cable de 3 pines al motor de rotaci√≥n de la mu√±eca y con√©ctelo a la placa controladora. Al igual que con el motor anterior, aseg√∫rese de que sea el √∫nico motor conectado a la placa y que el motor en s√≠ no est√© conectado a ning√∫n otro.

:::caution
Repita la operaci√≥n para cada motor seg√∫n las instrucciones.
:::

Verifique su cableado en cada paso antes de presionar Enter. Por ejemplo, el cable de la fuente de alimentaci√≥n podr√≠a desconectarse mientras manipula la placa.

Cuando haya terminado, el script simplemente finalizar√°, momento en el cual los motores estar√°n listos para ser utilizados. Ahora puede conectar el cable de 3 pines de cada motor al siguiente, y el cable del primer motor (el 'giro del hombro' con id=1) a la placa controladora, que ahora puede ser fijada a la base del brazo.

Haga los mismos pasos para el brazo l√≠der.

```bash
python -m lerobot.setup_motors \
    --teleop.type=so101_leader \
    --teleop.port=/dev/ttyACM0  # <- paste here the port found at previous step
```

<div class="video-container">
<iframe width="900" height="600" src="https://www.youtube.com/embed/hbW6eFYkHTg?si=jKdpTyI8wRC-iHxO" title="youtube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
</div>

</TabItem>

</Tabs>

## Ensamblaje

:::tip

- El proceso de ensamblaje de brazo dual del SO-ARM101 es el mismo que el del SO-ARM100. Las √∫nicas diferencias son la adici√≥n de clips de cable en el SO-ARM101 y las diferentes relaciones de engranajes de los servos de las articulaciones en el Brazo L√≠der. Por lo tanto, tanto el SO100 como el SO101 pueden instalarse siguiendo el siguiente contenido
- Antes del ensamblaje, verifique nuevamente su modelo de motor y relaci√≥n de reducci√≥n. Si ha comprado SO100, puede ignorar este paso. Si ha comprado SO101, verifique la siguiente tabla para distinguir F1 a F6 y L1 a L6.

:::

  | Modelo de Servo                            | Relaci√≥n de Engranajes | Articulaciones Correspondientes         |
|----------------------------------------|------------|------------------------------|
| ST-3215-C044(7.4V)                            | 1:191      | L1                           |
| ST-3215-C001(7.4V)                       | 1:345      | L2                           |
| ST-3215-C044(7.4V)                           | 1:191      | L3                           |
| ST-3215-C046(7.4V)                           | 1:147      | L4‚ÄìL6                        |
| ST-3215-C001(7.4V) / C018(12V) / C047(12V)             | 1:345      | F1‚ÄìF6                        |

:::danger
Si compr√≥ el **SO101 Arm Kit Standard Edition**, todas las fuentes de alimentaci√≥n son de 5V. Si compr√≥ el **SO101 Arm Kit Pro Edition**, el Brazo L√≠der debe calibrarse y operarse en cada paso usando una fuente de alimentaci√≥n de 5V, mientras que el Brazo Seguidor debe calibrarse y operarse en cada paso usando una fuente de alimentaci√≥n de 12V.
:::

**Ensamblar Brazo L√≠der**

| **Paso 1** | **Paso 2** | **Paso 3** | **Paso 4** | **Paso 5** | **Paso 6** |
|:---------:|:---------:|:---------:|:---------:|:---------:|:---------:|
| ![fig1](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_L1.jpg) | ![fig2](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_L2.jpg) | ![fig3](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_L3.jpg) |![fig4](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_L4.jpg) |![fig5](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_L5.jpg) |![fig6](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_L6.jpg) |
| **Paso 7** | **Paso 8** | **Paso 9** | **Paso 10** | **Paso 11** | **Paso 12** |
| ![fig1](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_L7.jpg) | ![fig2](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_L8.jpg) | ![fig3](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_L9.jpg) |![fig4](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_L10.jpg) |![fig5](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_L11.jpg) |![fig6](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_L12.jpg) |
| **Paso 13** | **Paso 14** | **Paso 15** | **Paso 16** | **Paso 17** | **Paso 18** |
| ![fig1](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_L13.jpg) | ![fig2](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_L14.jpg) | ![fig3](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_L15.jpg) |![fig4](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_L16.jpg) |![fig5](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_L18.jpg) |![fig6](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_L21.jpg) |
| **Paso 19** | **Paso 20** |
| ![fig1](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_L22.jpg) | ![fig2](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_L23.jpg) |

**Ensamblar Brazo Seguidor**

:::tip

- Los pasos para ensamblar el Brazo Seguidor son generalmente los mismos que los del Brazo L√≠der. La √∫nica diferencia radica en el m√©todo de instalaci√≥n del efector final (pinza y mango) despu√©s del Paso 12.

:::

| **Paso 1** | **Paso 2** | **Paso 3** | **Paso 4** | **Paso 5** | **Paso 6** |
|:---------:|:---------:|:---------:|:---------:|:---------:|:---------:|
| ![fig1](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_F1.jpg) | ![fig2](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_F2.jpg) | ![fig3](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_F3.jpg) |![fig4](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_F3.5.jpg) |![fig5](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_F4.jpg) |![fig6](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_F5.jpg) |
| **Paso 7** | **Paso 8** | **Paso 9** | **Paso 10** | **Paso 11** | **Paso 12** |
| ![fig1](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_F6.jpg) | ![fig2](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_F7.jpg) | ![fig3](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_F8.jpg) |![fig4](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_F9.jpg) |![fig5](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_F11.jpg) |![fig6](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_F12.jpg) |
| **Paso 13** | **Paso 14** | **Paso 15** | **Paso 16** | **Paso 17** |
| ![fig1](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_F13.jpg) | ![fig2](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_F14.jpg) | ![fig3](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_F15.jpg) |![fig4](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_F16.jpg) |![fig5](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_F17.jpg) |

## Calibrar

:::tip
Los c√≥digos del SO100 y SO101 son compatibles. Los usuarios del SO100 pueden utilizar directamente los par√°metros y c√≥digo del SO101 para la operaci√≥n.
:::

:::danger
Si compr√≥ el **SO101 Arm Kit Standard Edition**, todas las fuentes de alimentaci√≥n son de 5V. Si compr√≥ el **SO101 Arm Kit Pro Edition**, el Brazo L√≠der debe calibrarse y operarse en cada paso usando una fuente de alimentaci√≥n de 5V, mientras que el Brazo Seguidor debe calibrarse y operarse en cada paso usando una fuente de alimentaci√≥n de 12V.
:::

A continuaci√≥n, necesita conectar la fuente de alimentaci√≥n y el cable de datos a su robot SO-10x para la calibraci√≥n para asegurar que los brazos l√≠der y seguidor tengan los mismos valores de posici√≥n cuando est√©n en la misma posici√≥n f√≠sica. Esta calibraci√≥n es esencial porque permite que una red neuronal entrenada en un robot SO-10x funcione en otro. Si necesita recalibrar el brazo rob√≥tico, elimine los archivos bajo `~/.cache/huggingface/lerobot/calibration/robots` o `~/.cache/huggingface/lerobot/calibration/teleoperators` y recalibre el brazo rob√≥tico. De lo contrario, aparecer√° un mensaje de error. La informaci√≥n de calibraci√≥n del brazo rob√≥tico se almacenar√° en los archivos JSON bajo este directorio.

**Calibraci√≥n manual del brazo seguidor**

Conecte las interfaces de los 6 servos del robot mediante un cable de 3 pines y conecte el servo del chasis a la placa de accionamiento del servo, luego ejecute el siguiente comando o ejemplo de API para calibrar el brazo rob√≥tico:

***Primero se otorgan permisos de interfaz***

```bash
sudo chmod 666 /dev/ttyACM*
```
***Luego calibra el brazo seguidor***

```python
python -m lerobot.calibrate \
    --robot.type=so101_follower \
    --robot.port=/dev/ttyACM0 \
    --robot.id=my_awesome_follower_arm
```

El video a continuaci√≥n muestra c√≥mo realizar la calibraci√≥n. Primero necesitas mover el robot a la posici√≥n donde todas las articulaciones est√©n en el medio de sus rangos. Luego, despu√©s de presionar enter, tienes que mover cada articulaci√≥n a trav√©s de su rango completo de movimiento.

**Calibraci√≥n manual del brazo l√≠der**

Realiza los mismos pasos para calibrar el brazo l√≠der, ejecuta el siguiente comando o ejemplo de API:

```python
python -m lerobot.calibrate \
    --teleop.type=so101_leader \
    --teleop.port=/dev/ttyACM0 \
    --teleop.id=my_awesome_leader_arm
```

<div class="video-container">
<iframe width="900" height="600" src="https://www.youtube.com/embed/22n6f5xH9Dk?si=2QTzn1CDbsSv6Y_H" title="youtube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
</div>

## Teleoperar

**Teleoperaci√≥n simple**
¬°Entonces est√°s listo para teleoperar tu robot! Ejecuta este script simple (no se conectar√° ni mostrar√° las c√°maras):

Ten en cuenta que el id asociado con un robot se usa para almacenar el archivo de calibraci√≥n. Es importante usar el mismo id al teleoperar, grabar y evaluar cuando uses la misma configuraci√≥n.

```bash
sudo chmod 666 /dev/ttyACM*
```

```bash
python -m lerobot.teleoperate \
    --robot.type=so101_follower \
    --robot.port=/dev/ttyACM1 \
    --robot.id=my_awesome_follower_arm \
    --teleop.type=so101_leader \
    --teleop.port=/dev/ttyACM0 \
    --teleop.id=my_awesome_leader_arm
```

El comando teleoperate autom√°ticamente:

1. Identificar√° cualquier calibraci√≥n faltante e iniciar√° el procedimiento de calibraci√≥n.
2. Conectar√° el robot y el dispositivo de teleoperaci√≥n e iniciar√° la teleoperaci√≥n.

<div class="video-container">
<iframe width="900" height="600" src="https://www.youtube.com/embed/hnRwfcyX1ZI?si=RuzYjP_FUTK16lfs" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
</div>

## Agregar c√°maras

:::tip
Los c√≥digos SO100 y SO101 son compatibles. Los usuarios de SO100 pueden utilizar directamente los par√°metros y c√≥digo de SO101 para la operaci√≥n.
:::

Para instanciar una c√°mara, necesitas un identificador de c√°mara. Este identificador podr√≠a cambiar si reinicias tu computadora o reconectas tu c√°mara, un comportamiento que depende principalmente de tu sistema operativo.

Para encontrar los √≠ndices de c√°mara de las c√°maras conectadas a tu sistema, ejecuta el siguiente script:

```python
python -m lerobot.find_cameras opencv # or realsense for Intel Realsense cameras
```

La terminal imprimir√° la siguiente informaci√≥n.

```markdown
--- Detected Cameras ---
Camera #0:
  Name: OpenCV Camera @ 0
  Type: OpenCV
  Id: 0
  Backend api: AVFOUNDATION
  Default stream profile:
    Format: 16.0
    Width: 1920
    Height: 1080
    Fps: 15.0
--------------------
(more cameras ...)
```

Puedes encontrar las im√°genes tomadas por cada c√°mara en el directorio `outputs/captured_images`.

:::warning
Al usar c√°maras Intel RealSense en , podr√≠as obtener este error: , esto se puede resolver ejecutando el mismo comando con permisos. Ten en cuenta que usar c√°maras RealSense en es inestable.macOSError finding RealSense cameras: failed to set power statesudomacOS.
:::

Entonces podr√°s mostrar las c√°maras en tu computadora mientras teleoper√°s ejecutando el siguiente c√≥digo. Esto es √∫til para preparar tu configuraci√≥n antes de grabar tu primer conjunto de datos.

```bash
python -m lerobot.teleoperate \
    --robot.type=so101_follower \
    --robot.port=/dev/ttyACM1 \
    --robot.id=my_awesome_follower_arm \
    --robot.cameras="{ front: {type: opencv, index_or_path: 0, width: 640, height: 480, fps: 30}}" \
    --teleop.type=so101_leader \
    --teleop.port=/dev/ttyACM0 \
    --teleop.id=my_awesome_leader_arm \
    --display_data=true
```

Si tienes m√°s c√°maras, puedes cambiar `--robot.cameras` para agregar c√°maras. Debes notar el formato del index_or_path, que est√° determinado por el √∫ltimo d√≠gito del ID de c√°mara mostrado por `python -m lerobot.find_cameras opencv`.

Por ejemplo, quieres agregar una c√°mara lateral:

```bash
python -m lerobot.teleoperate \
    --robot.type=so101_follower \
    --robot.port=/dev/ttyACM1 \
    --robot.id=my_awesome_follower_arm \
    --robot.cameras="{ front: {type: opencv, index_or_path: 0, width: 640, height: 480, fps: 30}, side: {type: opencv, index_or_path: 2, width: 640, height: 480, fps: 30}}" \
    --teleop.type=so101_leader \
    --teleop.port=/dev/ttyACM0 \
    --teleop.id=my_awesome_leader_arm \
    --display_data=true
```

:::tip
Si encuentras un error como este.

<div align="center">
    <img width={800}
    src="https://files.seeedstudio.com/wiki/robotics/projects/lerobot/starai/rerun-version.png" />
</div>

Puedes degradar la versi√≥n de rerun para resolver el problema.

```bash
pip3 install rerun-sdk==0.23
```

:::

<div class="video-container">
<iframe width="900" height="600" src="https://www.youtube.com/embed/EUcXlLlOjGE?si=6ncQ7o5ZFLR4PGTU" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
</div>

## Grabar el conjunto de datos

- Si quieres guardar el conjunto de datos localmente, puedes ejecutarlo directamente:

```bash
python -m lerobot.record \
    --robot.type=so101_follower \
    --robot.port=/dev/ttyACM1 \
    --robot.id=my_awesome_follower_arm \
    --robot.cameras="{ front: {type: opencv, index_or_path: 0, width: 640, height: 480, fps: 30}, side: {type: opencv, index_or_path: 2, width: 640, height: 480, fps: 30}}" \
    --teleop.type=so101_leader \
    --teleop.port=/dev/ttyACM0 \
    --teleop.id=my_awesome_leader_arm \
    --display_data=true \
    --dataset.repo_id=seeedstudio123/test \
    --dataset.num_episodes=5 \
    --dataset.single_task="Grab the black cube" \
    --dataset.push_to_hub=false \
    --dataset.episode_time_s=30 \
    --dataset.reset_time_s=30 
```

Entre ellos, `repo_id` se puede modificar de forma personalizada, y `push_to_hub=false`. Finalmente, el conjunto de datos se guardar√° en el directorio `~/.cache/huggingface/lerobot` en la carpeta home, donde se crear√° la carpeta `seeedstudio123/test` mencionada anteriormente.

- Si quieres usar las funciones del hub de Hugging Face para subir tu conjunto de datos y no lo has hecho previamente, aseg√∫rate de haber iniciado sesi√≥n usando un token de acceso de escritura, que se puede generar desde la [configuraci√≥n de Hugging Face](https://huggingface.co/settings/tokens):

```bash
huggingface-cli login --token ${HUGGINGFACE_TOKEN} --add-to-git-credential
```

Almacena el nombre de tu repositorio de Hugging Face en una variable para ejecutar estos comandos:

```bash
HF_USER=$(huggingface-cli whoami | head -n 1)
echo $HF_USER
```

Graba 5 episodios y sube tu conjunto de datos al hub:

```bash
python -m lerobot.record \
    --robot.type=so101_follower \
    --robot.port=/dev/ttyACM1 \
    --robot.id=my_awesome_follower_arm \
    --robot.cameras="{ front: {type: opencv, index_or_path: 0, width: 640, height: 480, fps: 30}, side: {type: opencv, index_or_path: 2, width: 640, height: 480, fps: 30}}" \
    --teleop.type=so101_leader \
    --teleop.port=/dev/ttyACM0 \
    --teleop.id=my_awesome_leader_arm \
    --display_data=true \
    --dataset.repo_id=${HF_USER}/record-test \
    --dataset.num_episodes=5 \
    --dataset.single_task="Grab the black cube" \
    --dataset.push_to_hub=true \
    --dataset.episode_time_s=30 \
    --dataset.reset_time_s=30 
```

Ver√°s muchas l√≠neas apareciendo como esta:

```bash
INFO 2024-08-10 15:02:58 ol_robot.py:219 dt:33.34 (30.0hz) dtRlead: 5.06 (197.5hz) dtWfoll: 0.25 (3963.7hz) dtRfoll: 6.22 (160.7hz) dtRlaptop: 32.57 (30.7hz) dtRphone: 33.84 (29.5hz)
```

**Explicaciones de Par√°metros**

- episode-time-s: Representa el tiempo para recopilar datos cada vez.
- reset-time-s: Es el tiempo de preparaci√≥n entre cada recopilaci√≥n de datos.
- num-episodes: Indica cu√°ntos grupos de datos se espera recopilar.
- push-to-hub: Determina si subir los datos al HuggingFace Hub.

:::tip

- "Si quieres guardar los datos localmente (`--dataset.push_to_hub=false`), reemplaza `--dataset.repo_id=${HF_USER}/so101_test` con un nombre de carpeta local personalizado, como `--dataset.repo_id=seeed_123/so101_test`. Entonces se almacenar√° en el directorio home del sistema en `~/.cache/huggingface/lerobot`."

- Si subiste tu conjunto de datos al hub con `--dataset.push_to_hub=true`, puedes [visualizar tu conjunto de datos en l√≠nea](https://huggingface.co/spaces/lerobot/visualize_dataset) copiando y pegando tu repo id dado por:

- Presiona la flecha derecha ‚Üí en cualquier momento durante la grabaci√≥n del episodio para detener temprano e ir al reinicio. Lo mismo durante el reinicio, para detener temprano e ir a la siguiente grabaci√≥n de episodio.

- Presiona la flecha izquierda ‚Üê en cualquier momento durante la grabaci√≥n del episodio o reinicio para detener temprano, cancelar el episodio actual y volver a grabarlo.

- Presiona escape ESC en cualquier momento durante la grabaci√≥n del episodio para terminar la sesi√≥n temprano e ir directamente a la codificaci√≥n de video y subida del conjunto de datos.

- Nota: Los puntos de control se crean autom√°ticamente durante la grabaci√≥n. Si ocurre un problema, puedes reanudar ejecutando el mismo comando con `--resume=true`. Para comenzar a grabar desde cero, elimina manualmente el directorio del conjunto de datos.
- Una vez que te sientas c√≥modo con la grabaci√≥n de datos, puedes crear un conjunto de datos m√°s grande para el entrenamiento. Una buena tarea inicial es agarrar un objeto en diferentes ubicaciones y colocarlo en un contenedor. Sugerimos grabar al menos 50 episodios, con 10 episodios por ubicaci√≥n. Mant√©n las c√°maras fijas y conserva un comportamiento de agarre consistente durante todas las grabaciones. Tambi√©n aseg√∫rate de que el objeto que est√°s manipulando sea visible en las c√°maras. Una buena regla general es que deber√≠as poder realizar la tarea t√∫ mismo solo mirando las im√°genes de la c√°mara.

- En las siguientes secciones, entrenar√°s tu red neuronal. Despu√©s de lograr un rendimiento de agarre confiable, puedes comenzar a introducir m√°s variaciones durante la recolecci√≥n de datos, como ubicaciones de agarre adicionales, diferentes t√©cnicas de agarre y alteraci√≥n de las posiciones de la c√°mara.

- Evita agregar demasiada variaci√≥n muy r√°pidamente, ya que puede perjudicar tus resultados.

- En Linux, si las teclas de flecha izquierda y derecha y la tecla escape no tienen ning√∫n efecto durante la grabaci√≥n de datos, aseg√∫rate de haber configurado la variable de entorno $DISPLAY. Ver [limitaciones de pynput](https://pynput.readthedocs.io/en/latest/limitations.html#linux).

:::

<div class="video-container">
<iframe width="900" height="600" src="https://www.youtube.com/embed/wc-qh7UFkuQ?si=-eDB73KgUksyJXa-" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
</div>

## Visualizar el conjunto de datos

:::tip
Los c√≥digos SO100 y SO101 son compatibles. Los usuarios de SO100 pueden utilizar directamente los par√°metros y c√≥digo de SO101 para la operaci√≥n.
:::

```bash
echo ${HF_USER}/so101_test  
```

Si no subiste con `--dataset.push_to_hub=false`, tambi√©n puedes visualizarlo localmente con:

```bash
python -m lerobot.scripts.visualize_dataset_html \
  --repo-id ${HF_USER}/so101_test \
```

Si subes con `--dataset.push_to_hub=false`, tambi√©n puedes visualizarlo localmente con:

```bash
python -m lerobot.scripts.visualize_dataset_html \
  --repo-id seeed_123/so101_test \
```

**Aqu√≠, `seeed_123` es el nombre personalizado de `repo_id` definido al recopilar datos.**

<div align="center">
    <img width={800}
    src="https://files.seeedstudio.com/wiki/robotics/projects/lerobot/visualize_datasets.png" />
</div>

## Reproducir un episodio

:::tip
Los c√≥digos SO100 y SO101 son compatibles. Los usuarios de SO100 pueden utilizar directamente los par√°metros y c√≥digo de SO101 para la operaci√≥n.
:::

Ahora intenta reproducir el primer episodio en tu robot:

```bash
python -m lerobot.replay \
    --robot.type=so101_follower \
    --robot.port=/dev/ttyACM1 \
    --robot.id=my_awesome_follower_arm \
    --dataset.repo_id=${HF_USER}/record-test \
    --dataset.episode=0
```

## Entrenar una pol√≠tica

:::tip
Los c√≥digos SO100 y SO101 son compatibles. Los usuarios de SO100 pueden utilizar directamente los par√°metros y c√≥digo de SO101 para la operaci√≥n.
:::

Para entrenar una pol√≠tica para controlar tu robot, usa el script python -m lerobot.scripts.train. Se requieren algunos argumentos. Aqu√≠ tienes un comando de ejemplo:

```bash
python -m lerobot.scripts.train \
  --dataset.repo_id=${HF_USER}/so101_test \
  --policy.type=act \
  --output_dir=outputs/train/act_so101_test \
  --job_name=act_so101_test \
  --policy.device=cuda \
  --wandb.enable=false \
  --steps=300000 
```

**Si quieres entrenar en un conjunto de datos local, aseg√∫rate de que el `repo_id` coincida con el usado durante la recolecci√≥n de datos y agrega `--policy.push_to_hub=False`.**

```bash
python -m lerobot.scripts.train \
  --dataset.repo_id=seeedstudio123/test \
  --policy.type=act \
  --output_dir=outputs/train/act_so101_test \
  --job_name=act_so101_test \
  --policy.device=cuda \
  --wandb.enable=false \
  --policy.push_to_hub=false\
  --steps=300000 
```

Vamos a explicarlo:

- **Especificaci√≥n del conjunto de datos**: Proporcionamos el conjunto de datos a trav√©s del par√°metro `--dataset.repo_id=${HF_USER}/so101_test`.
- **Pasos de entrenamiento**: Modificamos el n√∫mero de pasos de entrenamiento usando `--steps=300000`. El algoritmo por defecto usa 800000 pasos, y puedes ajustarlo seg√∫n la dificultad de tu tarea y observando la p√©rdida durante el entrenamiento.
- **Tipo de pol√≠tica**: Proporcionamos la pol√≠tica con `policy.type=act`. De manera similar, puedes cambiar entre pol√≠ticas como [act, diffusion, pi0, pi0fast, pi0fast, sac, smolvla]., que cargar√° la configuraci√≥n desde `configuration_act.py`. Importante, esta pol√≠tica se adaptar√° autom√°ticamente a los estados del motor de tu robot (por ejemplo, `laptop` y `phone`), acciones del motor y el n√∫mero de c√°maras, ya que esta informaci√≥n ya est√° almacenada en tu conjunto de datos.
- **Selecci√≥n de dispositivo**: Proporcionamos `policy.device=cuda` porque estamos entrenando en una GPU Nvidia, pero puedes usar `policy.device=mps` para entrenar en Apple Silicon.
- **Herramienta de visualizaci√≥n**: Proporcionamos `wandb.enable=true` para visualizar gr√°ficos de entrenamiento usando [Weights and Biases](https://docs.wandb.ai/quickstart). Esto es opcional, pero si lo usas, aseg√∫rate de haber iniciado sesi√≥n ejecutando `wandb login`.

Si encuentras el siguiente error:

<div align="center">
    <img width={1000}
    src="https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/stack_bug.png" />
</div>

Intenta ejecutar el siguiente comando para resolverlo:

```bash
pip install datasets==2.19
```

El entrenamiento deber√≠a tomar varias horas. Encontrar√°s puntos de control en `outputs/train/act_so100_test/checkpoints`.

Para reanudar el entrenamiento desde un punto de control, a continuaci√≥n se muestra un comando de ejemplo para reanudar desde el √∫ltimo punto de control de la pol√≠tica `act_so101_test`:

```bash
python -m lerobot.scripts.train \
  --config_path=outputs/train/act_so101_test/checkpoints/last/pretrained_model/train_config.json \
  --resume=true
```

**Subir puntos de control de pol√≠tica**

Una vez que el entrenamiento est√© terminado, sube el √∫ltimo punto de control con:

```bash
huggingface-cli upload ${HF_USER}/act_so101_test \
  outputs/train/act_so101_test/checkpoints/last/pretrained_model
```

Tambi√©n puedes subir puntos de control intermedios con:

```bash
CKPT=010000
huggingface-cli upload ${HF_USER}/act_so101_test${CKPT} \
  outputs/train/act_so101_test/checkpoints/${CKPT}/pretrained_model
```

## Evaluar tu pol√≠tica

:::tip
Los c√≥digos SO100 y SO101 son compatibles. Los usuarios de SO100 pueden utilizar directamente los par√°metros y c√≥digo de SO101 para la operaci√≥n.
:::

Puedes usar la funci√≥n `record` de [`lerobot/record.py`](https://github.com/huggingface/lerobot/blob/main/lerobot/record.py) pero con un punto de control de pol√≠tica como entrada. Por ejemplo, ejecuta este comando para grabar 10 episodios de evaluaci√≥n:

```bash
python -m lerobot.record  \
  --robot.type=so100_follower \
  --robot.port=/dev/ttyACM1 \
  --robot.cameras="{ up: {type: opencv, index_or_path: /dev/video10, width: 640, height: 480, fps: 30}, side: {type: intelrealsense, serial_number_or_name: 233522074606, width: 640, height: 480, fps: 30}}" \
  --robot.id=my_awesome_follower_arm \
  --display_data=false \
  --dataset.repo_id=${HF_USER}/eval_so100 \
  --dataset.single_task="Put lego brick into the transparent box" \
  --policy.path=${HF_USER}/my_policy
```

como:

```bash
python -m lerobot.record  \
  --robot.type=so101_follower \
  --robot.port=/dev/ttyACM1 \
  --robot.cameras="{ front: {type: opencv, index_or_path: 0, width: 640, height: 480, fps: 30},   side: {type: opencv, index_or_path: 2, width: 640, height: 480, fps: 30}}" \
  --robot.id=my_awesome_follower_arm \
  --display_data=false \
  --dataset.repo_id=seeed/eval_test123 \
  --dataset.single_task="Put lego brick into the transparent box" \
  --policy.path=outputs/train/act_so101_test/checkpoints/last/pretrained_model
```

1. El par√°metro `--policy.path` indica la ruta al archivo de pesos de los resultados de entrenamiento de tu pol√≠tica (por ejemplo, `outputs/train/act_so101_test/checkpoints/last/pretrained_model`). Si subes el archivo de pesos del resultado del entrenamiento del modelo a Hub, tambi√©n puedes usar el repositorio del modelo (por ejemplo, `${HF_USER}/act_so100_test`).

2. El nombre del conjunto de datos `dataset.repo_id` comienza con `eval_`. Esta operaci√≥n grabar√° por separado videos y datos durante la evaluaci√≥n, que se guardar√°n en la carpeta que comience con `eval_`, como `seeed/eval_test123`.

3. Si encuentras `File exists: 'home/xxxx/.cache/huggingface/lerobot/xxxxx/seeed/eval_xxxx'` durante la fase de evaluaci√≥n, por favor elimina primero la carpeta que comience con `eval_` y luego ejecuta el programa nuevamente.

4. Cuando encuentres `mean is infinity. You should either initialize with stats as an argument or use a pretrained model`, ten en cuenta que las palabras clave como front y side en el par√°metro `--robot.cameras` deben ser estrictamente consistentes con las usadas al recopilar el conjunto de datos.

<div class="video-container">
<iframe width="900" height="600" src="https://www.youtube.com/embed/wc-qh7UFkuQ?si=Y2SXU9T0DSmtz4ll" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
</div>

## FAQ

- Si est√°s siguiendo esta documentaci√≥n/tutorial, por favor clona el repositorio de GitHub recomendado `https://github.com/Seeed-Projects/lerobot.git`. El repositorio recomendado en esta documentaci√≥n es una versi√≥n estable verificada; el repositorio oficial de Lerobot se actualiza continuamente a la √∫ltima versi√≥n, lo que puede causar problemas imprevistos como diferentes versiones de conjuntos de datos, diferentes comandos, etc.

- Si encuentras el siguiente error al calibrar los IDs de servo:

  ```bash
  `Motor ‚Äògripper‚Äô was not found, Make sure it is connected`
  ```

  Por favor verifica cuidadosamente si el cable de comunicaci√≥n est√° conectado correctamente al servo y si la fuente de alimentaci√≥n est√° proporcionando el voltaje correcto.

- Si encuentras:

  ```bash
  Could not connect on port "/dev/ttyACM0"
  ```

  Y puedes ver que ACM0 existe al ejecutar `ls /dev/ttyACM*`, significa que olvidaste otorgar permisos del puerto serie. Ingresa `sudo chmod 666 /dev/ttyACM*` en la terminal para solucionarlo.

- Si encuentras:

  ```bash
  No valid stream found in input file. Is -1 of the desired media type?
  ```
  Por favor instala ffmpeg 7.1.1 usando `conda install ffmpeg=7.1.1 -c conda-forge`.

<div align="center">
    <img width={800}
    src="https://files.seeedstudio.com/wiki/robotics/projects/lerobot/lekiwi/No valid stream.png" />
</div>

- Si encuentras:

  ```bash
  ConnectionError: Failed to sync read 'Present_Position' on ids=[1,2,3,4,5,6] after 1 tries. [TxRxResult] There is no status packet!
  ```

  Necesitas verificar si el brazo rob√≥tico en el puerto correspondiente est√° encendido, y si los cables de datos de los servos del bus est√°n sueltos o desconectados. Si la luz de un servo no est√° encendida, significa que el cable del servo anterior est√° suelto.

- Si encuentras el siguiente error al calibrar el brazo rob√≥tico:

  ```bash
  Magnitude 30841 exceeds 2047 (max for sign_bit_index=11)
  ```

  Apaga y reinicia el brazo rob√≥tico, luego intenta calibrar nuevamente. Este m√©todo tambi√©n se puede usar si el √°ngulo MAX alcanza un valor de decenas de miles durante la calibraci√≥n. Si esto no funciona, necesitas recalibrar los servos correspondientes, incluyendo la calibraci√≥n mediana y la escritura de ID.

- Si encuentras durante la fase de evaluaci√≥n:

  ```bash
  File exists: 'home/xxxx/.cache/huggingface/lerobot/xxxxx/seeed/eval_xxxx'
  ```

  Por favor elimina primero la carpeta que comience con `eval_` y luego ejecuta el programa nuevamente.

- Si encuentras durante la fase de evaluaci√≥n:

  ```bash
  `mean` is infinity. You should either initialize with `stats` as an argument or use a pretrained model
  ```

  Ten en cuenta que las palabras clave como "front" y "side" en el par√°metro `--robot.cameras` deben ser estrictamente consistentes con las utilizadas al recopilar el conjunto de datos.

- Si has reparado o reemplazado partes del brazo rob√≥tico, por favor elimina completamente los archivos bajo `~/.cache/huggingface/lerobot/calibration/robots` o `~/.cache/huggingface/lerobot/calibration/teleoperators` y recalibra el brazo rob√≥tico. De lo contrario, pueden aparecer mensajes de error, ya que la informaci√≥n de calibraci√≥n se almacena en archivos JSON en estos directorios.

- Entrenar ACT en 50 conjuntos de datos toma aproximadamente 6 horas en una laptop con RTX 3060 (8GB), y alrededor de 2-3 horas en computadoras con GPUs RTX 4090 o A100.

- Durante la recopilaci√≥n de datos, aseg√∫rate de que la posici√≥n de la c√°mara, el √°ngulo y la iluminaci√≥n ambiental sean estables. Reduce la cantidad de fondo inestable y peatones capturados por la c√°mara, ya que cambios excesivos en el entorno de despliegue pueden causar que el brazo rob√≥tico falle al agarrar correctamente.

- Para el comando de recopilaci√≥n de datos, aseg√∫rate de que el par√°metro `num-episodes` est√© configurado para recopilar datos suficientes. No pauses manualmente a la mitad, ya que la media y la varianza de los datos se calculan solo despu√©s de que se complete la recopilaci√≥n de datos, las cuales son necesarias para el entrenamiento.

- Si el programa indica que no puede leer datos de imagen de la c√°mara USB, aseg√∫rate de que la c√°mara USB no est√© conectada a trav√©s de un hub. La c√°mara USB debe estar conectada directamente al dispositivo para garantizar una velocidad de transmisi√≥n de imagen r√°pida.

- Si encuentras un error como `AttributeError: module 'rerun' has no attribute 'scalar'. Did you mean: 'scalars'?`, puedes degradar la versi√≥n de rerun para resolver el problema.

```bash
pip3 install rerun-sdk==0.23
```

:::tip
Si encuentras problemas de software o problemas de dependencias del entorno que no se pueden resolver, adem√°s de verificar la secci√≥n de FAQ al final de este tutorial, por favor reporta el problema oportunamente a la [plataforma LeRobot](https://github.com/huggingface/lerobot) o al [canal de Discord de LeRobot](https://discord.gg/8TnwDdjFGU).
:::

## Cita

[‰∏≠ÊñáÊñáÊ°£](https://wiki.seeedstudio.com/cn/lerobot_so100m_new/)

Proyecto TheRobotStudio: [SO-ARM10x](https://github.com/TheRobotStudio/SO-ARM100)

Proyecto Huggingface: [Lerobot](https://github.com/huggingface/lerobot/tree/main)

Dnsty: [Jetson Containers](https://github.com/dusty-nv/jetson-containers/tree/master/packages/robots/lerobot)

[Jetson AI Lab](https://www.jetson-ai-lab.com/lerobot.html)

[Diffusion Policy](https://diffusion-policy.cs.columbia.edu/)

[ACT or ALOHA](https://tonyzhaozh.github.io/aloha/)

[TDMPC](https://www.nicklashansen.com/td-mpc/)

[VQ-BeT](https://sjlee.cc/vq-bet/)

## Soporte T√©cnico y Discusi√≥n del Producto

¬°Gracias por elegir nuestros productos! Estamos aqu√≠ para brindarte diferentes tipos de soporte para asegurar que tu experiencia con nuestros productos sea lo m√°s fluida posible. Ofrecemos varios canales de comunicaci√≥n para satisfacer diferentes preferencias y necesidades.

<div class="button_tech_support_container">
<a href="https://forum.seeedstudio.com/" class="button_forum"></a>
<a href="https://www.seeedstudio.com/contacts" class="button_email"></a>
</div>

<div class="button_tech_support_container">
<a href="https://discord.gg/eWkprNDMU7" class="button_discord"></a>
<a href="https://github.com/Seeed-Studio/wiki-documents/discussions/69" class="button_discussion"></a>
</div>
