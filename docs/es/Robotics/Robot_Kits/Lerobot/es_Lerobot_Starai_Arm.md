---
description: Este wiki proporciona el tutorial de depuraci√≥n para el Brazo Rob√≥tico StarAI y realiza la recolecci√≥n de datos y entrenamiento dentro del marco de trabajo Lerobot.
title: Comenzando con el Brazo Rob√≥tico StarAI con LeRobot
keywords:
- Lerobot
- Huggingface
- Arm
- Robotics 
image: https://files.seeedstudio.com/wiki/robotics/projects/lerobot/starai/starai_robotic_arm.webp
slug: /es/lerobot_starai_arm
last_update:
  date: 9/1/2025
  author: LiShanghang
---

# Comenzando con el Brazo Rob√≥tico StarAI con LeRobot

:::tip
 [LeRobot](https://github.com/huggingface/lerobot/tree/main) est√° comprometido a proporcionar modelos, conjuntos de datos y herramientas para rob√≥tica del mundo real en PyTorch. Su objetivo es reducir la barrera de entrada de la rob√≥tica, permitiendo que todos contribuyan y se beneficien del intercambio de conjuntos de datos y modelos preentrenados. LeRobot integra metodolog√≠as de vanguardia validadas para aplicaciones del mundo real, centr√°ndose en el aprendizaje por imitaci√≥n. Ha proporcionado un conjunto de modelos preentrenados, conjuntos de datos con demostraciones recopiladas por humanos y entornos de simulaci√≥n, permitiendo a los usuarios comenzar sin la necesidad de ensamblar robots. En las pr√≥ximas semanas, la intenci√≥n es aumentar el soporte para rob√≥tica del mundo real en los robots m√°s rentables y competentes actualmente accesibles.
:::

## Introducci√≥n del Producto

1.  **C√≥digo Abierto y F√°cil para Desarrollo Secundario**
    Esta serie de servomotores, proporcionada por [Fashion Robotics](https://fashionrobo.com/), ofrece una soluci√≥n de brazo rob√≥tico de c√≥digo abierto y f√°cilmente personalizable de 6+1 grados de libertad.

2.  **Soporte de Integraci√≥n con la Plataforma LeRobot**
    Est√° espec√≠ficamente dise√±ado para integraci√≥n con la [plataforma LeRobot](https://github.com/huggingface/lerobot). Esta plataforma proporciona modelos PyTorch, conjuntos de datos y herramientas para aprendizaje por imitaci√≥n en tareas de rob√≥tica del mundo real, incluyendo recolecci√≥n de datos, simulaci√≥n, entrenamiento y despliegue.

3.  **Abundantes Recursos de Aprendizaje**
    Ofrecemos recursos de aprendizaje de c√≥digo abierto integrales, incluyendo configuraci√≥n de entorno, gu√≠as de instalaci√≥n y depuraci√≥n, y ejemplos de tareas de agarre personalizadas para ayudar a los usuarios a comenzar r√°pidamente y desarrollar aplicaciones rob√≥ticas.

4.  **Compatibilidad con Plataforma Nvidia**
    El despliegue es compatible a trav√©s de la plataforma reComputer Mini J4012 Orin NX 16GB.

<div class="video-container">
<iframe width="900" height="600" src="https://www.youtube.com/embed/IJKTeBYAG7k?si=iS-jqT27fDjeI6yX" title="youtube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
</div>

<div class="get_one_now_container" style={{textAlign: 'center'}}>
<a class="get_one_now_item" href="https://www.seeedstudio.com/Fashionstar-Star-Arm-Viola-Violin-p-6497.html">
            <strong><span><font color={'FFFFFF'} size={"4"}> ¬°Consigue Uno Ahora! üñ±Ô∏è</font></span></strong>
</a></div>


## Caracter√≠sticas Clave

- Listo para Usar -- Sin Ensamblaje Requerido. Solo Desempaca y Sum√©rgete en el Mundo de la IA.
- 6+1 Grados de Libertad y un Alcance de 470mm -- Construido para Versatilidad y Precisi√≥n.
- Alimentado por Servos de Bus Sin Escobillas Duales -- Suave, Silencioso y Fuerte con hasta 300g de Carga √ötil.
- Pinza Paralela con Apertura M√°xima de 66mm -- Puntas de Dedos Modulares para Flexibilidad de Reemplazo R√°pido.
- Tecnolog√≠a Exclusiva de Bloqueo Flotante -- Congela Instant√°neamente el Brazo L√≠der en Cualquier Posici√≥n con una Sola Presi√≥n.

## Especificaciones

  <div align="center">
      <img width={800}
      src="https://files.seeedstudio.com/wiki/robotics/projects/lerobot/starai/Specifications.png" />
  </div>

| Elemento             | Brazo Seguidor \| Viola                           | Brazo L√≠der \|Violin                              |
| -------------------- | ------------------------------------------------- | ------------------------------------------------- |
| Grados de Libertad   | 6                                                 | 6+1                                               |
| Alcance              | 470mm                                             | 470mm                                             |
| Envergadura          | 940mm                                             | 940mm                                             |
| Repetibilidad        | 2mm                                               | -                                                 |
| Carga √ötil de Trabajo| 300g (con 70% de Alcance)                        | -                                                 |
| Servos               | RX8-U50H-M x2<br/>RA8-U25H-M x4<br/>RA8-U26H-M x1 | RX8-U50H-M x2<br/>RA8-U25H-M x4<br/>RA8-U26H-M x1 |
| Kit de Pinza Paralela| ‚úÖ                                                 | -                                                 |
| Rotaci√≥n de Mu√±eca   | S√≠                                                | S√≠                                                |
| Mantener en Cualquier Posici√≥n | S√≠                                      | S√≠ (con bot√≥n de mango)                           |
| Montaje de C√°mara en Mu√±eca | ‚úÖ                                          | -                                                 |
| Funciona con LeRobot | ‚úÖ                                                 | ‚úÖ                                                 |
| Funciona con ROS 2   | ‚úÖ                                                 | /                                                 |
| Funciona con MoveIt  | ‚úÖ                                                 | /                                                 |
| Funciona con Gazebo  | ‚úÖ                                                 | /                                                 |
| Hub de Comunicaci√≥n  | UC-01                                             | UC-01                                             |
| Fuente de Alimentaci√≥n | 12v/120w                                        | 12v/120w                                          |

Para m√°s informaci√≥n sobre servomotores, por favor visita el siguiente enlace.

[RA8-U25H-M](https://fashionrobo.com/actuator-u25/23396/)

[RX18-U100H-M](https://fashionrobo.com/actuator-u100/22853/)

[RX8-U50H-M](https://fashionrobo.com/actuator-u50/136/)


## Configuraci√≥n inicial del entorno

**Para Ubuntu x86:**
- Ubuntu 22.04  
- CUDA 12+  
- Python 3.10  
- Torch 2.6  

**Para Jetson Orin:**
- Jetson JetPack 6.0+  
- Python 3.10  
- Torch 2.6  

## Instalaci√≥n y Depuraci√≥n

### Instalar LeRobot

Entornos como pytorch y torchvision necesitan ser instalados bas√°ndose en tu CUDA.
1. Instalar Miniconda:
Para Jetson:

```bash
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh
chmod +x Miniconda3-latest-Linux-aarch64.sh
./Miniconda3-latest-Linux-aarch64.sh
source ~/.bashrc
```

O, Para X86 Ubuntu 22.04:
```bash
mkdir -p ~/miniconda3
cd miniconda3
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.sh
bash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3
rm ~/miniconda3/miniconda.sh
source ~/miniconda3/bin/activate
conda init --all
```

2. Crear y activar un entorno conda fresco para lerobot

```bash
conda create -y -n lerobot python=3.10 && conda activate lerobot
```

3. Clonar Lerobot:

```bash
git clone https://github.com/servodevelop/lerobot-starai.git
```

4. Cuando uses miniconda, instala ffmpeg en tu entorno:

```bash
conda install ffmpeg -c conda-forge
```

:::tip
Esto usualmente instala ffmpeg 7.X para tu plataforma compilado con el codificador libsvtav1. Si libsvtav1 no es compatible (verifica codificadores compatibles con ffmpeg -encoders), puedes:
- [En cualquier plataforma] Instalar expl√≠citamente ffmpeg 7.X usando:
```bash
conda install ffmpeg=7.1.1 -c conda-forge
```
- [Solo en Linux] Instalar dependencias de construcci√≥n de ffmpeg y compilar ffmpeg desde el c√≥digo fuente con libsvtav1, y aseg√∫rate de usar el binario ffmpeg correspondiente a tu instalaci√≥n con which ffmpeg.

:::

5. Instalar LeRobot con dependencias para los motores feetech:

```bash
cd ~/lerobot-starai && pip install -e ".[feetech]"
```


Para dispositivos Jetson Jetpack (por favor aseg√∫rate de instalar [Pytorch-gpu y Torchvision](https://github.com/Seeed-Projects/reComputer-Jetson-for-Beginners/blob/main/3-Basic-Tools-and-Getting-Started/3.3-Pytorch-and-Tensorflow/README.md#installing-pytorch-on-recomputer-nvidia-jetson) desde el paso 5 antes de ejecutar este paso):

```bash
conda install -y -c conda-forge "opencv>=4.10.0.84"  # Install OpenCV and other dependencies through conda, this step is only for Jetson Jetpack 6.0+
conda remove opencv   # Uninstall OpenCV 
pip3 install opencv-python==4.10.0.84  # Then install opencv-python via pip3
conda install -y -c conda-forge ffmpeg
conda uninstall numpy
pip3 install numpy==1.26.0  # This should match torchvision
```


6. Verificar Pytorch y Torchvision

Dado que instalar el entorno lerobot v√≠a pip desinstalar√° el Pytorch y Torchvision originales e instalar√° las versiones CPU de Pytorch y Torchvision, necesitas realizar una verificaci√≥n en Python.

```python
import torch
print(torch.cuda.is_available())
```

Si el resultado impreso es False, necesitas reinstalar Pytorch y Torchvision seg√∫n el [tutorial del sitio web oficial](https://pytorch.org/index.html).

Si est√°s usando un dispositivo Jetson, instala Pytorch y Torchvision seg√∫n [este tutorial](https://github.com/Seeed-Projects/reComputer-Jetson-for-Beginners/blob/main/3-Basic-Tools-and-Getting-Started/3.3-Pytorch-and-Tensorflow/README.md#installing-pytorch-on-recomputer-nvidia-jetson).




### Desempacando el Brazo Rob√≥tico

El Kit de Brazo Rob√≥tico Incluye

- Brazo l√≠der
- Brazo seguidor
- Controlador (mango)
- Pinza paralela
- Herramientas de instalaci√≥n (tornillos, llave hexagonal)
- Fuente de alimentaci√≥n √ó2
- Abrazadera en C √ó2
- Placa de depuraci√≥n UC-01 √ó2

Interruptor de la placa de depuraci√≥n UC-01Ôºö

<div align="center">
    <img width={800}
    src="https://files.seeedstudio.com/wiki/robotics/projects/lerobot/starai/UC-01 debuging board switch.png" />
</div>

### Configurar Puerto del Brazo

Ejecuta el siguiente comando en la terminal para encontrar puertos USB asociados a tus brazosÔºö

```bash
python lerobot/scripts/find_motors_bus_port.py
```

:::tip
Recuerda quitar el usb, de lo contrario la interfaz no ser√° detectada.
:::

Por ejemploÔºö

1. Salida de ejemplo al identificar el puerto del brazo l√≠der (ej., `/dev/tty.usbmodem575E0031751` en Mac, o posiblemente `/dev/ttyACM0` en Linux):
2. Salida de ejemplo al identificar el puerto del brazo seguidor (ej., `/dev/tty.usbmodem575E0032081` en Mac, o posiblemente `/dev/ttyACM1` en Linux):
Es posible que necesites dar acceso a los puertos USB ejecutando:

```bash
sudo chmod 666 /dev/ttyACM0
sudo chmod 666 /dev/ttyACM1
```

:::tip

Si no se puede identificar el puerto serie ttyUSB0, prueba las siguientes soluciones:

Lista todos los puertos USB.

```sh
lsusb
```

<div align="center">
    <img width={800}
    src="https://files.seeedstudio.com/wiki/robotics/projects/lerobot/starai/Calibrate1.png" />
</div>

Una vez identificado, verifica la informaci√≥n del ttyusb.

```sh
sudo dmesg | grep ttyUSB
```

<div align="center">
    <img width={800}
    src="https://files.seeedstudio.com/wiki/robotics/projects/lerobot/starai/Calibrate2.png" />
</div>

La √∫ltima l√≠nea indica una desconexi√≥n porque brltty est√° ocupando el USB. Eliminar brltty resolver√° el problema.

```sh
sudo apt remove brltty
```

<div align="center">
    <img width={800}
    src="https://files.seeedstudio.com/wiki/robotics/projects/lerobot/starai/Calibrate3.png" />
</div>

Finalmente, usa el comando chmod.

```sh
sudo chmod 666 /dev/ttyUSB0
```
:::


Abre el archivo `lerobot-starai\lerobot\common\robot_devices\robots\configs.py`

Usa Ctrl+F para buscar starai y localizar el siguiente c√≥digo. Luego, necesitas modificar la configuraci√≥n de puerto de follower_arms y leader_arms para que coincida con la configuraci√≥n de puerto real.

```python
@RobotConfig.register_subclass("starai")
@dataclass
class StaraiRobotConfig(ManipulatorRobotConfig):
    calibration_dir: str = ".cache/calibration/starai"
    max_relative_target: int | None = None

    leader_arms: dict[str, MotorsBusConfig] = field(
        default_factory=lambda: {
            "main": StaraiMotorsBusConfig(
                port="/dev/ttyUSB1",  #<-------- UPDATE HEARE
                interval = 100,								
                motors={
                    # name: (index, model)
                    "joint1": [0, "rx8-u50"],
                    "joint2": [1, "rx8-u50"],
                    "joint3": [2, "rx8-u50"],
                    "joint4": [3, "rx8-u50"],
                    "joint5": [4, "rx8-u50"],
                    "joint6": [5, "rx8-u50"],
                    "gripper": [6, "rx8-u50"],
                },
            ),
        }
    )

    follower_arms: dict[str, MotorsBusConfig] = field(
        default_factory=lambda: {
            "main": StaraiMotorsBusConfig(
                port="/dev/ttyUSB0",  #<-------- UPDATE HEARE
                interval = 100,								
                motors={
                    # name: (index, model)
                    "joint1": [0, "rx8-u50"],
                    "joint2": [1, "rx8-u50"],
                    "joint3": [2, "rx8-u50"],
                    "joint4": [3, "rx8-u50"],
                    "joint5": [4, "rx8-u50"],
                    "joint6": [5, "rx8-u50"],
                    "gripper": [6, "rx8-u50"],
                },
            ),
        }
    )
```

### Configurar Par√°metros de Tiempo de Ejecuci√≥n

Abre el archivo `lerobot-starai\lerobot\common\robot_devices\robots\configs.py`

Usa Ctrl + F para buscar starai y localizar el siguiente c√≥digo. Luego, necesitas modificar la configuraci√≥n de intervalo de follower_arms.

- Descripci√≥n: El seguidor responde m√°s r√°pido cuando el intervalo de tiempo se vuelve menor, y funciona de manera m√°s estable cuando el intervalo de tiempo se vuelve mayor.
- Rango de Valores: Entero, mayor que 50 y menor que 2000.

Se recomienda configurar el intervalo a 100 (valor predeterminado) durante la teleoperaci√≥n para una mejor capacidad de respuesta, y a 1000 durante la ejecuci√≥n aut√≥noma en fases de evaluaci√≥n para asegurar un movimiento m√°s estable.

```python
@RobotConfig.register_subclass("starai")
@dataclass
class StaraiRobotConfig(ManipulatorRobotConfig):
    calibration_dir: str = ".cache/calibration/starai"
    max_relative_target: int | None = None

    leader_arms: dict[str, MotorsBusConfig] = field(
        default_factory=lambda: {
            "main": StaraiMotorsBusConfig(
                port="/dev/ttyUSB1",
                interval = 100, 	#<-------- UPDATE HEARE							
                motors={
                    # name: (index, model)
                    "joint1": [0, "rx8-u50"],
                    "joint2": [1, "rx8-u50"],
                    "joint3": [2, "rx8-u50"],
                    "joint4": [3, "rx8-u50"],
                    "joint5": [4, "rx8-u50"],
                    "joint6": [5, "rx8-u50"],
                    "gripper": [6, "rx8-u50"],
                },
            ),
        }
    )

    follower_arms: dict[str, MotorsBusConfig] = field(
        default_factory=lambda: {
            "main": StaraiMotorsBusConfig(
                port="/dev/ttyUSB0",
                interval = 100, 	#<-------- UPDATE HEARE
                motors={
                    # name: (index, model)
                    "joint1": [0, "rx8-u50"],
                    "joint2": [1, "rx8-u50"],
                    "joint3": [2, "rx8-u50"],
                    "joint4": [3, "rx8-u50"],
                    "joint5": [4, "rx8-u50"],
                    "joint6": [5, "rx8-u50"],
                    "gripper": [6, "rx8-u50"],
                },
            ),
        }
    )

```

### Calibrar

Normalmente, el brazo rob√≥tico est√° pre-calibrado en f√°brica y no requiere recalibraci√≥n. Si se encuentra que un motor de articulaci√≥n permanece en una posici√≥n l√≠mite durante un per√≠odo prolongado, por favor cont√°ctanos para obtener el archivo de calibraci√≥n y realizar la recalibraci√≥n nuevamente.


## Teleoperar

<div class="video-container">
<iframe width="900" height="600" src="https://www.youtube.com/embed/Uz-x-2P2xaE?si=HJTjALt5yFntR6-s" title="youtube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
</div>

Mueve el brazo a la posici√≥n mostrada en el diagrama y ponlo en espera.

<div align="center">
    <img width={800}
    src="https://files.seeedstudio.com/wiki/robotics/projects/lerobot/starai/Specifications.png" />
</div>

**Teleoperaci√≥n simple**
¬°Entonces est√°s listo para teleoperar tu robot! Ejecuta este script simple (no se conectar√° ni mostrar√° las c√°maras):

```bash
python lerobot/scripts/control_robot.py \
  --robot.type=starai \
  --robot.cameras='{}' \
  --control.type=teleoperate
```

Despu√©s de que el programa inicie, el bot√≥n Hold permanece funcional.



## Agregar c√°maras

<div class="video-container">
<iframe width="900" height="600" src="https://www.youtube.com/embed/-p8K_-XxW8U?si=UmYWvEyKNPpTRxDC" title="youtube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
</div>

Despu√©s de insertar tus dos c√°maras USB, ejecuta el siguiente script para verificar los n√∫meros de puerto de las c√°maras. Es importante recordar que la c√°mara no debe estar conectada a un Hub USB; en su lugar, debe estar conectada directamente al dispositivo. La velocidad m√°s lenta de un Hub USB puede resultar en la incapacidad de leer datos de imagen.

```bash
python lerobot/common/robot_devices/cameras/opencv.py \
    --images-dir outputs/images_from_opencv_cameras
```

La terminal imprimir√° la siguiente informaci√≥n. Por ejemplo, la c√°mara del port√°til es `index 0`, y la c√°mara USB es `index 2`.

```markdown
Mac or X86 Ubuntu detected. Finding available camera indices through scanning all indices from 0 to 60
[...]
Camera found at index 0
Camera found at index 2
[...]
Connecting cameras
OpenCVCamera(0, fps=30.0, width=640, height=480, color_mode=rgb)
OpenCVCamera(2, fps=30.0, width=640, height=480, color_mode=rgb)
Saving images to outputs/images_from_opencv_cameras
Frame: 0000 Latency (ms): 39.52
[...]
Frame: 0046 Latency (ms): 40.07
Images have been saved to outputs/images_from_opencv_cameras
```

Puedes encontrar las im√°genes tomadas por cada c√°mara en el directorio `outputs/images_from_opencv_cameras`, y confirmar la informaci√≥n del √≠ndice de puerto correspondiente a las c√°maras en diferentes posiciones. Luego completa la alineaci√≥n de los par√°metros de la c√°mara en el archivo `lerobot-starai/lerobot/common/robot_devices/robots/configs.py`.

<div align="center">
    <img width={400}
    src="https://files.seeedstudio.com/wiki/robotics/projects/lerobot/starai/camera.png" />
</div>


```python
@RobotConfig.register_subclass("starai")
@dataclass
class StaraiRobotConfig(ManipulatorRobotConfig):
    calibration_dir: str = ".cache/calibration/starai"

    cameras: dict[str, CameraConfig] = field(
        default_factory=*lambda*: {
            "laptop": OpenCVCameraConfig(
                camera_index=2,             #<------ UPDATE HEARE
                fps=30,
                width=640,
                height=480,
            ),
            "phone": OpenCVCameraConfig(
                camera_index=0,             #<------ UPDATE HEARE
                fps=30,
                width=640,
                height=480,
            ),
        }
    )

‚Äã    mock: bool = False

```

Entonces podr√°s mostrar las c√°maras en tu computadora mientras est√©s teleoperando:

```bash
python lerobot/scripts/control_robot.py \
  --robot.type=starai \
  --control.type=teleoperate \
  --control.display_data=true
```

:::tip
Si encuentras un error como este.

<div align="center">
    <img width={800}
    src="https://files.seeedstudio.com/wiki/robotics/projects/lerobot/starai/rerun-version.png" />
</div>

Puedes degradar la versi√≥n de rerun para resolver el problema.

```bash
pip3 install rerun-sdk==0.23
```

:::

## Grabar el conjunto de datos

<div class="video-container">
<iframe width="900" height="600" src="https://www.youtube.com/embed/OpaC0CA3-Mc?si=rbNhJJRkG9zngQB-" title="youtube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
</div>

Una vez que est√©s familiarizado con la teleoperaci√≥n, puedes grabar tu primer conjunto de datos.

Si quieres usar las funciones del hub de Hugging Face para subir tu conjunto de datos y no lo has hecho previamente, aseg√∫rate de haber iniciado sesi√≥n usando un token de acceso de escritura, que se puede generar desde la [configuraci√≥n de Hugging Face](https://huggingface.co/settings/tokens):
```bash
huggingface-cli login --token ${HUGGINGFACE_TOKEN} --add-to-git-credential
```

Almacena el nombre de tu repositorio de Hugging Face en una variable para ejecutar estos comandos:

```bash
HF_USER=$(huggingface-cli whoami | head -n 1)
echo $HF_USER
```

:::tip
Si no deseas usar la funci√≥n de carga de conjuntos de datos del Hub de Hugging Face, puedes optar por `--control.push_to_hub=false`. Adem√°s, reemplaza `--control.repo_id=${HF_USER}/starai` con un nombre de carpeta local personalizado, como `--control.repo_id=starai/starai`. Los datos se almacenar√°n en el directorio `~/.cache/huggingface/lerobot` bajo el directorio home del sistema.
:::

Graba 20 episodios y sube tu conjunto de datos al hub:

```bash
python lerobot/scripts/control_robot.py \
  --robot.type=starai \
  --control.type=record \
  --control.fps=30 \
  --control.single_task="Grasp a lego block and put it in the bin." \
  --control.repo_id=${HF_USER}/starai \
  --control.tags='["starai","tutorial"]' \
  --control.warmup_time_s=5 \
  --control.episode_time_s=30 \
  --control.reset_time_s=30 \
  --control.num_episodes=20 \
  --control.display_data=true \
  --control.push_to_hub=ture
```

No subir al Hub:
**(Recomendado, los siguientes tutoriales se enfocar√°n principalmente en datos locales)** 

```bash
python lerobot/scripts/control_robot.py \
  --robot.type=starai \
  --control.type=record \
  --control.fps=30 \
  --control.single_task="Grasp a lego block and put it in the bin." \
  --control.repo_id=starai/starai \#Assign a name to the local storage file yourself
  --control.tags='["starai","tutorial"]' \
  --control.warmup_time_s=5 \
  --control.episode_time_s=30 \
  --control.reset_time_s=30 \
  --control.num_episodes=20 \
  --control.display_data=true \
  --control.push_to_hub=false #set push_to_hub to false
```

Ver√°s datos similares a los siguientes:
```bash
INFO 2024-08-10 15:02:58 ol_robot.py:219 dt:33.34 (30.0hz) dtRlead: 5.06 (197.5hz) dtWfoll: 0.25 (3963.7hz) dtRfoll: 6.22 (160.7hz) dtRlaptop: 32.57 (30.7hz) dtRphone: 33.84 (29.5hz)
```

```markdown
Parameter Explanations
- wormup-time-s: It refers to the initialization time.
- episode-time-s: It represents the time for collecting data each time.
- reset-time-s: It is the preparation time between each data collection.
- num-episodes: It indicates how many groups of data are expected to be collected.
- push-to-hub: It determines whether to upload the data to the HuggingFace Hub. 
```

:::tip

- **De nuevo**: "Si quieres guardar los datos localmente (`--control.push_to_hub=false`), reemplaza `--control.repo_id=${HF_USER}/starai` con un nombre de carpeta local personalizado, como `--control.repo_id=starai/starai`. Entonces se almacenar√° en el directorio home del sistema en `~/.cache/huggingface/lerobot`."

- Nota: Puedes reanudar la grabaci√≥n agregando `--control.resume=true`. Tambi√©n si a√∫n no has subido tu conjunto de datos, agrega `--control.local_files_only=true`. Necesitar√°s eliminar manualmente el directorio del conjunto de datos si quieres empezar a grabar desde cero.

- Si subiste tu conjunto de datos al hub con `--control.push_to_hub=true`, puedes [visualizar tu conjunto de datos en l√≠nea](https://huggingface.co/spaces/lerobot/visualize_dataset) copiando y pegando tu repo id dado por:

- Presiona la flecha derecha ‚Üí en cualquier momento durante la grabaci√≥n del episodio para detener temprano e ir al reinicio. Lo mismo durante el reinicio, para detener temprano e ir a la grabaci√≥n del siguiente episodio.

- Presiona la flecha izquierda ‚Üê en cualquier momento durante la grabaci√≥n del episodio o reinicio para detener temprano, cancelar el episodio actual y volver a grabarlo.

- Presiona escape ESC en cualquier momento durante la grabaci√≥n del episodio para terminar la sesi√≥n temprano e ir directamente a la codificaci√≥n de video y carga del conjunto de datos.

- Una vez que te sientas c√≥modo con la grabaci√≥n de datos, puedes crear un conjunto de datos m√°s grande para entrenamiento. Una buena tarea inicial es agarrar un objeto en diferentes ubicaciones y colocarlo en un contenedor. Sugerimos grabar al menos 50 episodios, con 10 episodios por ubicaci√≥n. Mant√©n las c√°maras fijas y mant√©n un comportamiento de agarre consistente durante las grabaciones. Tambi√©n aseg√∫rate de que el objeto que est√°s manipulando sea visible en las c√°maras. Una buena regla general es que deber√≠as poder hacer la tarea t√∫ mismo solo mirando las im√°genes de la c√°mara.

- En las siguientes secciones, entrenar√°s tu red neuronal. Despu√©s de lograr un rendimiento de agarre confiable, puedes comenzar a introducir m√°s variaciones durante la recolecci√≥n de datos, como ubicaciones de agarre adicionales, diferentes t√©cnicas de agarre y alterar las posiciones de la c√°mara.

- Evita agregar demasiada variaci√≥n muy r√°pidamente, ya que puede obstaculizar tus resultados.

- En Linux, si las teclas de flecha izquierda y derecha y la tecla escape no tienen efecto durante la grabaci√≥n de datos, aseg√∫rate de haber configurado la variable de entorno $DISPLAY. Ver [limitaciones de pynput](https://pynput.readthedocs.io/en/latest/limitations.html#linux).

:::


## Visualizar el conjunto de datos

El conjunto de datos se guarda localmente. Puedes visualizarlo localmente con:

```bash
python lerobot/scripts/visualize_dataset_html.py \
  --repo-id starai/starai \
```

Aqu√≠, `starai/starai` es el nombre personalizado de `repo_id` definido al recopilar datos.

## Reproducir un episodio

Ahora intenta reproducir el primer episodio en tu robot:

```bash
python lerobot/scripts/control_robot.py \
  --robot.type=starai \
  --control.type=replay \
  --control.fps=30 \
  --control.repo_id=starai/starai \
  --control.episode=0 \# 0 is the first episode
  --control.local_files_only=true
```

:::tip
El par√°metro `--control.local_files_only=true` se usa para instruir al programa a utilizar conjuntos de datos locales en lugar de los del Hub.
:::

## Entrenar una pol√≠tica

Para entrenar una pol√≠tica para controlar tu robot, usa el script `python lerobot/scripts/train.py`. Se requieren algunos argumentos. Aqu√≠ hay un comando de ejemplo:

```bash
python lerobot/scripts/train.py \
  --dataset.repo_id=starai/starai \
  --policy.type=act \
  --output_dir=outputs/train/act_starai \
  --job_name=act_starai \
  --policy.device=cuda \
  --wandb.enable=false
```

Vamos a explicarlo:

1. Usamos nuestro conjunto de datos local como argumento `--dataset.repo_id=starai/starai`.
2. Proporcionamos la pol√≠tica usando `policy.type=act`, que cargar√° la configuraci√≥n desde [`lerobot-starai/lerobot/common/policies/act/configuration_act.py`](https://github.com/huggingface/lerobot/blob/main/lerobot/common/policies/act/configuration_act.py). Actualmente, ACT ha sido probado, pero tambi√©n puedes probar otras pol√≠ticas como diffusion, pi0, pi0fast, tdmpc y vqbet.
3. Proporcionamos policy.device=cuda ya que estamos entrenando en una GPU Nvidia, pero podr√≠as usar policy.device=mps para entrenar en silicio de Apple.
4. Proporcionamos `wandb.enable=true` para usar [Weights and Biases](https://docs.wandb.ai/quickstart) para visualizar gr√°ficos de entrenamiento. Esto es opcional pero si lo usas, aseg√∫rate de estar conectado ejecutando `wandb login`.

Si quieres entrenar en un conjunto de datos local, aseg√∫rate de que el `repo_id` coincida con el usado durante la recolecci√≥n de datos. El entrenamiento deber√≠a tomar varias horas. Encontrar√°s checkpoints en `outputs/train/act_starai/checkpoints`.

Para reanudar el entrenamiento desde un checkpoint, a continuaci√≥n hay un comando de ejemplo para reanudar desde el √∫ltimo checkpoint del `act_starai`:

```bash
python lerobot/scripts/train.py \
  --config_path=outputs/train/act_starai/checkpoints/last/pretrained_model/train_config.json \
  --resume=true
```

## Evaluar tu pol√≠tica

Puedes usar la funci√≥n `record` de [`lerobot/scripts/control_robot.py`](https://github.com/huggingface/lerobot/blob/main/lerobot/scripts/control_robot.py), pero con un checkpoint de pol√≠tica como entrada. Por ejemplo, ejecuta este comando para grabar 10 episodios de evaluaci√≥n:

```bash
python lerobot/scripts/control_robot.py \
  --robot.type=starai \
  --control.type=record \
  --control.fps=30 \
  --control.single_task="Grasp a lego block and put it in the bin." \
  --control.repo_id=starai/eval_act_starai \
  --control.tags='["tutorial"]' \
  --control.warmup_time_s=5 \
  --control.episode_time_s=30 \
  --control.reset_time_s=0 \#Set the reset time to 0 to skip the reset phase and ensure continuous operation.
  --control.num_episodes=10 \
  --control.push_to_hub=false \#Choose don't upload to Hub
  --control.policy.path=outputs/train/act_starai/checkpoints/last/pretrained_model
```

Como puedes ver, esto es casi id√©ntico al comando usado previamente para grabar el conjunto de datos de entrenamiento. Solo hay dos diferencias:

1. Se ha agregado el par√°metro `--control.policy.path` para indicar la ruta de tu checkpoint de pol√≠tica (por ejemplo, `outputs/train/act_starai/checkpoints/last/pretrained_model`).
2. El nombre del conjunto de datos de evaluaci√≥n **debe** comenzar con `eval` para reflejar que est√°s ejecutando inferencia (por ejemplo, `--control.repo_id=starai/eval_act_starai`). Esta operaci√≥n grabar√° videos y datos espec√≠ficamente durante la evaluaci√≥n y los guardar√° en `eval_act_starai`.

:::warning
Si ocurre un error cuando ejecutas el comando de evaluaci√≥n por segunda vez, necesitas eliminar el archivo correspondiente `eval_act_starai` para asegurar que no haya archivos con el mismo nombre bajo el directorio `~/.cache/huggingface/lerobot/starai/`.
:::

:::tip
Si subes tu checkpoint de modelo al Hub, tambi√©n puedes usar el repositorio del modelo (por ejemplo, `--control.repo_id=${HF_USER}/eval_act_starai`), mientras configuras `--control.push_to_hub=true`.
:::

## FAQ

- Si est√°s siguiendo esta documentaci√≥n/tutorial, por favor clona el repositorio de GitHub recomendado `git clone https://github.com/servodevelop/lerobot-starai.git`.

- Si encuentras el siguiente error, necesitas verificar si el brazo rob√≥tico conectado al puerto correspondiente est√° encendido y si los servos del bus tienen cables sueltos o desconectados.
  ```bash
  ConnectionError: Read failed due to comunication eror on port /dev/ttyACM0 for group key Present_Position_Shoulder_pan_Shoulder_lift_elbow_flex_wrist_flex_wrist_roll_griper: [TxRxResult] There is no status packet!
  ```

- Si has reparado o reemplazado cualquier parte del brazo rob√≥tico, por favor elimina completamente la carpeta `~/lerobot/.cache/huggingface/calibration/so100` y recalibra el brazo rob√≥tico.
- Si el control remoto funciona normalmente pero el control remoto con c√°mara no logra mostrar la interfaz de imagen, puedes encontrar [aqu√≠](https://github.com/huggingface/lerobot/pull/757/files)

- Si encuentras problemas con libtiff durante la operaci√≥n remota del conjunto de datos, por favor actualiza la versi√≥n de libtiff.
  ```bash
  conda install libtiff==4.5.0  #for Ubuntu 22.04 is libtiff==4.5.1
  ```

- Despu√©s de ejecutar la [Instalaci√≥n de Lerobot](https://wiki.seeedstudio.com/es/lerobot_so100m/#install-lerobot), la versi√≥n GPU de pytorch puede desinstalarse autom√°ticamente, por lo que necesitas instalar manualmente torch-gpu.

- Para Jetson, por favor instala primero [Pytorch y Torchvsion](https://github.com/Seeed-Projects/reComputer-Jetson-for-Beginners/blob/main/3-Basic-Tools-and-Getting-Started/3.3-Pytorch-and-Tensorflow/README.md#installing-pytorch-on-recomputer-nvidia-jetson) antes de ejecutar `conda install -y -c conda-forge ffmpeg`, de lo contrario, al compilar torchvision, puede ocurrir un problema de incompatibilidad de versi√≥n de ffmpeg.

- Si ocurre el siguiente problema, significa que tu computadora no soporta este formato de c√≥dec de video. Necesitas modificar la l√≠nea 134 en el archivo `lerobot-starai/lerobot/common/datasets/video_utils.py` cambiando el valor de `vcodec: str = "libsvtav1"` a `libx264` o `libopenh264`. Diferentes computadoras pueden requerir diferentes par√°metros, as√≠ que puedes probar varias opciones. [Issues 705](https://github.com/huggingface/lerobot/issues/705)

  ```bash
  [vost#0:0 @ 0x13207240] Unknown encoder 'libsvtav1' [vost#0:0 @ 0x13207240] Error selecting an encoder Error opening output file /home/han/.cache/huggingface/lerobot/lyhhan/so100_test/videos/chunk-000/observation.images.laptop/episode_000000.mp4. Error opening output files: Encoder not found
  ``` 

- ¬°¬°¬°Importante!!! Si durante la ejecuci√≥n el cable del servo se afloja, por favor restaura el servo a su posici√≥n inicial y luego reconecta el cable del servo. Tambi√©n puedes calibrar individualmente un servo usando el [Comando de Inicializaci√≥n del Servo](https://wiki.seeedstudio.com/es/lerobot_so100m/#configure-the-motors), asegur√°ndote de que solo un cable est√© conectado entre el servo y la placa del controlador durante la calibraci√≥n individual. Si encuentras
  ```bash
  Auto-correct calibration of motor 'wrist roll' by shifting value by 1 full turns, from '-270 < -312.451171875 < 270degrees' to'-270<-312.451171875 < 270 degrees'.
  ```
  u otros errores durante el proceso de calibraci√≥n del brazo rob√≥tico relacionados con √°ngulos y exceder valores l√≠mite, este m√©todo sigue siendo aplicable.

- Entrenar 50 conjuntos de datos ACT en una laptop 3060 de 8G toma aproximadamente 6 horas, mientras que en una computadora 4090 o A100, entrenar 50 conjuntos de datos toma alrededor de 2‚Äì3 horas.

- Durante la recolecci√≥n de datos, aseg√∫rate de que la posici√≥n, √°ngulo e iluminaci√≥n ambiental de la c√°mara permanezcan estables, y minimiza capturar fondos inestables excesivos y peatones; de lo contrario, cambios ambientales significativos durante el despliegue pueden causar que el brazo rob√≥tico falle al agarrar correctamente.

- Aseg√∫rate de que el par√°metro `num-episodes` en el comando de recolecci√≥n de datos est√© configurado para recolectar datos suficientes, y no hagas pausa manual a mitad de camino. Esto es porque la media y varianza de los datos se calculan solo despu√©s de que la recolecci√≥n de datos est√© completa, lo cual es necesario para el entrenamiento.

- Si el programa indica que no puede leer los datos de imagen de la c√°mara USB, por favor aseg√∫rate de que la c√°mara USB no est√© conectada a un hub. La c√°mara USB debe estar conectada directamente al dispositivo para asegurar una velocidad de transmisi√≥n de imagen r√°pida.

- Si encuentras un error como `AttributeError: module 'rerun' has no attribute 'scalar'. Did you mean: 'scalars'?`, puedes degradar la versi√≥n de rerun para resolver el problema.

```bash
pip3 install rerun-sdk==0.23
```

:::tip
Si encuentras problemas de software o problemas de dependencias del entorno que no se pueden resolver, adem√°s de revisar la secci√≥n FAQ al final de este tutorial, por favor reporta el problema oportunamente a la [plataforma LeRobot](https://github.com/huggingface/lerobot) o al [canal Discord de LeRobot](https://discord.gg/8TnwDdjFGU).
:::


## Cita

Documento Wiki en ingl√©s de SeeedstudioÔºö[C√≥mo usar el brazo rob√≥tico SO10xArm en la √∫ltima versi√≥n de Lerobot](https://wiki.seeedstudio.com/es/lerobot_so100m_new/)

lerobot-starai github: [lerobot-starai](https://github.com/Welt-liu/lerobot-starai)

STEP: [STEP](https://github.com/Welt-liu/star-arm-moveit2/tree/main/hardware)

URDF: [URDF](https://github.com/Welt-liu/star-arm-moveit2/tree/main/src/cello_description)

StarAI Robot Arm moveit2: [star-arm-moveit2](https://github.com/Welt-liu/star-arm-moveit2)

Proyecto Huggingface: [Lerobot](https://github.com/huggingface/lerobot/tree/main)

ACT o ALOHA: [Learning Fine-Grained Bimanual Manipulation with Low-Cost Hardware](https://tonyzhaozh.github.io/aloha/)

VQ-BeT: [VQ-BeT: Behavior Generation with Latent Actions](https://sjlee.cc/vq-bet/)

Diffusion Policy: [Diffusion Policy](https://diffusion-policy.cs.columbia.edu/)

TD-MPC: [TD-MPC](https://www.nicklashansen.com/td-mpc/)


## Soporte T√©cnico y Discusi√≥n de Productos

¬°Gracias por elegir nuestros productos! Estamos aqu√≠ para brindarte diferentes tipos de soporte para asegurar que tu experiencia con nuestros productos sea lo m√°s fluida posible. Ofrecemos varios canales de comunicaci√≥n para satisfacer diferentes preferencias y necesidades.

<div class="button_tech_support_container">
<a href="https://forum.seeedstudio.com/" class="button_forum"></a>
<a href="https://www.seeedstudio.com/contacts" class="button_email"></a>
</div>

<div class="button_tech_support_container">
<a href="https://discord.gg/eWkprNDMU7" class="button_discord"></a>
<a href="https://github.com/Seeed-Studio/wiki-documents/discussions/69" class="button_discussion"></a>
</div>


