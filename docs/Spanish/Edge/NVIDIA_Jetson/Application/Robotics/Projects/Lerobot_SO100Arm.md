---
description: This wiki provides the assembly and debugging tutorial for the SO ARM100 and realizes data collection and training within the Lerobot framework. 
title: How to use the SO100Arm robotic arm in Lerobot
keywords:
- Lerobot
- Huggingface
- Arm
- Robotics
image: https://files.seeedstudio.com/wiki/robotics/projects/lerobot/Arm_kit.webp
slug: /lerobot_so100m
last_update:
  date: 12/24/2024
  author: ZhuYaoHui
---

# C√≥mo utilizar el brazo rob√≥tico SO-ARM100 en Lerobot

## Introducci√≥n

El [SO-100ARM](https://github.com/TheRobotStudio/SO-ARM100) es un proyecto de brazo rob√≥tico totalmente de c√≥digo abierto lanzado por [TheRobotStudio](https://www.therobotstudio.com/). Incluye el brazo seguidor y el brazo rob√≥tico l√≠der, y tambi√©n proporciona archivos de impresi√≥n 3D detallados y gu√≠as de operaci√≥n. [LeRobot](https://github.com/huggingface/lerobot/tree/main) se compromete a proporcionar modelos, conjuntos de datos y herramientas para la rob√≥tica del mundo real en PyTorch. Su objetivo es reducir la barrera de entrada de la rob√≥tica, permitiendo que todos contribuyan y se beneficien al compartir conjuntos de datos y modelos previamente entrenados. LeRobot integra metodolog√≠as de vanguardia validadas para aplicaciones en el mundo real, centr√°ndose en el aprendizaje por imitaci√≥n y el aprendizaje por refuerzo. Ha proporcionado un conjunto de modelos previamente entrenados, conjuntos de datos con demostraciones recopiladas por humanos y entornos de simulaci√≥n, lo que permite a los usuarios comenzar sin la necesidad de ensamblar un robot. En las pr√≥ximas semanas, la intenci√≥n es aumentar el soporte para la rob√≥tica del mundo real en los robots m√°s rentables y competentes actualmente disponibles.

<iframe width="900" height="600" src="https://www.youtube.com/embed/sD34HnAkGNc?si=hqKd_sH5Oc9sdcwd" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

## Introducci√≥n al proyectos

El SO-ARM100 y el kit de robot inteligente reComputer Jetson AI combinan a la perfecci√≥n el control del brazo rob√≥tico de alta precisi√≥n con una potente plataforma inform√°tica de IA, proporcionando una soluci√≥n integral de desarrollo de robots. Este kit se basa en la plataforma Jetson Orin o AGX Orin, combinada con el brazo rob√≥tico SO-ARM100 y el marco de IA de LeRobot, ofreciendo a los usuarios un sistema de robot inteligente aplicable a m√∫ltiples escenarios como educaci√≥n, investigaci√≥n y automatizaci√≥n industrial.
Esta wiki proporciona el tutorial de ensamblaje y depuraci√≥n para SO ARM100 y realiza la recopilaci√≥n de datos y la capacitaci√≥n dentro del marco de Lerobot.

  <div align="center">
      <img width={800}
      src="https://files.seeedstudio.com/wiki/robotics/projects/lerobot/Arm_kit.png" />
  </div>

<div class="get_one_now_container" style={{textAlign: 'center'}}>
<a class="get_one_now_item" href="https://www.seeedstudio.com/SO-ARM100-Low-Cost-AI-Arm-Kit.html">
            <strong><span><font color={'FFFFFF'} size={"4"}> Conseguir uno üñ±Ô∏è</font></span></strong>
</a></div>

## Caracter√≠sticas principales

1. **Brazo rob√≥tico de alta precisi√≥n**: El brazo rob√≥tico SO-ARM100 emplea servomotores de alta precisi√≥n y algoritmos avanzados de control de movimiento, y es adecuado para una variedad de tareas como agarre, ensamblaje e inspecci√≥n.
2. **Plataforma reComputer Jetson**: utiliza SeeedStudio reComputer Jetson Orin o AGX Orin Dev Kit como plataforma inform√°tica de IA, que admite tareas de aprendizaje profundo, visi√≥n por computadora y procesamiento de datos, proporcionando potentes capacidades inform√°ticas.
3. **Impulsado por IA**: integra el marco de IA de LeRobot de Hugging Face, admite el procesamiento del lenguaje natural (NLP) y visi√≥n por computadora, lo que permite que el robot comprenda instrucciones de manera inteligente y perciba el entorno.
4. **C√≥digo abierto y expansi√≥n flexible**: Es una plataforma de c√≥digo abierto que es f√°cil de personalizar y expandir, adecuada para que desarrolladores e investigadores realicen desarrollo secundario y admite la integraci√≥n de m√∫ltiples sensores y herramientas.
5. **Aplicaci√≥n multiescena**: es aplicable a campos como la educaci√≥n, la investigaci√≥n cient√≠fica, la producci√≥n automatizada y la rob√≥tica, ayuda a los usuarios a lograr operaciones rob√≥ticas eficientes y precisas en diversas tareas complejas.

<iframe width="900" height="600" src="https://www.youtube.com/embed/JrF_ymUvrqc?si=vslu5NNI-ZIzVXLc" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

## Especificaciones

| Especificaci√≥n | Arm Kit | Arm Kit Pro |
|--|--|--|
| Tipo | Arm Kit | Arm Kit Pro |
| Grados de libertad | 6 | 6 |
| Torque m√°ximo | 19.5kg.cm 7.4V | 30kg.cm 12V |
| Servo | STS3215 Bus Servo | STS3215 Bus Servo |
| Alimentaci√≥n| 5.5mm*2.1mm DC 5V4A | 5.5mm*2.1mm DC 12V1A |
| Encoder | 12-bit magn√©tico | 12-bit magn√©tico |
| Rango de temperatura | 0‚ÑÉÔΩû40‚ÑÉ | 0‚ÑÉÔΩû40‚ÑÉ |
| Comunicaci√≥n | UART | UART |
| M√©todo de control | PC | PC |

## Lista de materiales

| Parte | Cantidad | ¬øIncluido? |
|--|--|--|
| STS3215 Servo1 | 12 | ‚úÖ |
| Placa de control de Motor | 2 | ‚úÖ |
| Cable USB-C | 1 | ‚úÖ |
| Fuente de alimentaci√≥n | 2 | ‚úÖ |
| Abrazadera de mesa | 1 | ‚ùå |
| Partes impresas en 3D del brazo | 1 | ‚ùå |

:::Precauci√≥n
Las piezas impresas en 3D y las abrazaderas de mesa no est√°n incluidas en el producto. Sin embargo, el SO-100ARM proporciona [archivos STL de impresi√≥n 3D](https://github.com/TheRobotStudio/SO-ARM100/tree/main/stl_files_for_3dprinting) detallados y par√°metros de impresi√≥n. Adem√°s, tambi√©n ofrecemos las [piezas impresas en 3D de la abrazadera de mesa](https://makerworld.com/zh/models/908660).
:::

## Gu√≠a de impresi√≥n 3D

Se acepta una variedad de impresoras 3D para imprimir las piezas necesarias del brazo seguidor y l√≠der. Sigue los pasos a continuaci√≥n para garantizar una impresi√≥n exitosa.

1. Elige una impresora: los archivos STL proporcionados est√°n listos para imprimir en muchas impresoras FDM. A continuaci√≥n se muestran las configuraciones probadas y sugeridas, aunque es posible que otras funcionen.
    - Material: PLA
    - Di√°metro de la boquilla y precisi√≥n: 0.4mm de di√°metro de boquilla a 0.2mm de altura de capa o 0.6mm de di√°metro de boquilla a 0.4mm de altura de capa.
    - Densidad de relleno (Infill): 13%

2. Adquisici√≥n de archivos de impresi√≥n 3D: Todas las piezas del l√≠der o seguidor est√°n contenidas en un √∫nico archivo, correctamente orientado de z hacia arriba para minimizar apoyos.

    Para tama√±os de cama de impresora de 220 mm x 220 mm (como la Ender), imprime:
    - [Print_Follower_SO_ARM100_08_Ender.STL](https://github.com/TheRobotStudio/SO-ARM100/blob/main/stl_files_for_3dprinting/Follower/Print_Follower_SO_ARM100_08k_Ender.STL)
    - [Print_Leader_SO_ARM100_08_Ender.STL](https://github.com/TheRobotStudio/SO-ARM100/blob/main/stl_files_for_3dprinting/Leader/Print_Leader_SO_ARM100_08k_Ender.STL)

    Para tama√±os de cama de impresora de 205 mm x 250 mm (como Prusa/Up), imprime:
    - [Print_Follower_SO_ARM100_08_UP_Prusa.STL](https://github.com/TheRobotStudio/SO-ARM100/blob/main/stl_files_for_3dprinting/Follower/Print_Follower_SO_ARM100_08k_UP_Prusa.STL)
    - [Print_Leader_SO_ARM100_08_UP_Prusa.STL](https://github.com/TheRobotStudio/SO-ARM100/blob/main/stl_files_for_3dprinting/Leader/Print_Leader_SO_ARM100_08k_UP_Prusa.STL)

Para facilitar la descarga, ya hemos empaquetado todos los archivos en la [plataforma Makerworld](https://makerworld.com/zh/models/908660), incluidas las abrazaderas de mesa.

## Instalar LeRobot

En tu reComputer Nvidia Jetson:

1. Instala Miniconda:

```bash
mkdir -p ~/miniconda3
cd ~/miniconda3
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh
chmod +x Miniconda3-latest-Linux-aarch64.sh
./Miniconda3-latest-Linux-aarch64.sh
```

2. Reinicia shell o `source ~/.bashrc`

3. Crea y activa un nuevo entorno conda para lerobot

```bash
conda create -y -n lerobot python=3.10 && conda activate lerobot
```

4. Clona Lerobot:

```bash
git clone https://github.com/huggingface/lerobot.git ~/lerobot
```

5. Instala LeRobot con dependencias para los motores feetech:

```bash
cd ~/lerobot && pip install -e ".[feetech]"
```

Solo para Linux (no para Mac), instala dependencias adicionales para registrar conjuntos de datos:

```bash
conda install -y -c conda-forge ffmpeg
pip uninstall -y opencv-python
conda install -y -c conda-forge "opencv>=4.10.0"
```

## Configura los motores

Sigue los pasos del [video de ensamblaje](https://www.youtube.com/watch?v=FioA2oeFZ5I) que ilustra el uso de nuestros scripts a continuaci√≥n.

<iframe width="900" height="600" src="https://www.youtube.com/embed/FioA2oeFZ5I?si=GjudmAovwF_X5m2f" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

**Encuentra puertos USB asociados a tus brazos**
Para encontrar los puertos correctos para cada brazo, ejecuta el script de la utilidad dos veces:

```bash
python lerobot/scripts/find_motors_bus_port.py
```

Ejemplo de salida al identificar el puerto del brazo l√≠der (por ejemplo, `/dev/tty.usbmodem575E0031751` en Mac, o posiblemente `/dev/ttyACM0` en Linux):

Ejemplo de salida al identificar el puerto del brazo seguidor (por ejemplo, `/dev/tty.usbmodem575E0032081`, o posiblemente `/dev/ttyACM1` en Linux):

Soluci√≥n de problemas: en Linux, es posible que necesites dar acceso a los puertos USB ejecutando:

```bash
sudo chmod 666 /dev/ttyACM0
sudo chmod 666 /dev/ttyACM1
```

**Configura tus motores**
Conecta tu primer motor y ejecuta este script para establecer su ID en 1. Tambi√©n establecer√° su posici√≥n actual en 2048, as√≠ que espera que tu motor gire:

```bash
python lerobot/scripts/configure_motor.py \
  --port /dev/ttyACM0 \
  --brand feetech \
  --model sts3215 \
  --baudrate 1000000 \
  --ID 1
```

Nota: Estos motores est√°n actualmente limitados. S√≥lo pueden tomar valores entre 0 y 4096, lo que corresponde a un giro completo. No pueden girar m√°s que eso. 2048 est√° en el medio de este rango, por lo que podemos tomar -2048 pasos (180 grados en el sentido contrario a las agujas del reloj) y alcanzar el rango m√°ximo, o tomar +2048 pasos (180 grados en el sentido de las agujas del reloj) y alcanzar el rango m√°ximo. El paso de configuraci√≥n tambi√©n establece el desplazamiento de referencia en 0, de modo que si no ensamblaste mal el brazo, siempre puedes actualizar el desplazamiento de referencia para tener en cuenta un desplazamiento de hasta ¬± 2048 pasos (¬± 180 grados).

Luego desenchufa tu motor y conecta el segundo motor y configura su ID en 2.

```bash
python lerobot/scripts/configure_motor.py \
  --port /dev/ttyACM0 \
  --brand feetech \
  --model sts3215 \
  --baudrate 1000000 \
  --ID 2
```

Vuelve a realizar el proceso para todos tus motores hasta el ID 6. Haz lo mismo para los 6 motores del brazo l√≠der.

## Ensambleje

Las instrucciones detalladas en v√≠deo se encuentran en [HuggingFace Youtube](https://www.youtube.com/watch?v=FioA2oeFZ5I)

<iframe width="900" height="600" src="https://www.youtube.com/embed/FioA2oeFZ5I?si=GjudmAovwF_X5m2f" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

## Calibraci√≥n

A continuaci√≥n, deber√°s calibrar tu robot SO-100 para asegurarte de que los brazos l√≠der y seguidor tengan los mismos valores de posici√≥n cuando est√©n en la misma posici√≥n f√≠sica. Esta calibraci√≥n es esencial porque permite que una red neuronal entrenada en un robot SO-100 funcione en otro.

:::info
La calibraci√≥n del brazo rob√≥tico debe realizarse estrictamente de acuerdo con los pasos de ["Calibrar"](https://github.com/huggingface/lerobot/blob/main/examples/10_use_so100.md#calibrate) en el tutorial oficial de Lerobot.
:::

**Calibraci√≥n manual del brazo seguidor**

En primer lugar, debes asegurarte de que los n√∫meros de puerto serie del brazo rob√≥tico en el archivo `\lerobot\lerobot\configs\robot\so100.yaml` sean consistentes con los tuyos, como se muestra en la siguiente figura. Puedes ver todos los nombres de los puertos serie seg√∫n `ls /dev/ttyACM*`.

<div align="center">
    <img width={800}
    src="https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so100yaml.png" />
</div>

Deber√°s mover el brazo seguidor a estas posiciones secuencialmente:

<iframe width="900" height="600" src="https://www.youtube.com/embed/m1z9Dlk1gW8?si=Ln2PFmPnap2AeDZc" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

Aseg√∫rate de que ambos brazos est√©n conectados y ejecuta este script para iniciar la calibraci√≥n manual:

```bash
python lerobot/scripts/control_robot.py calibrate \
    --robot-path lerobot/configs/robot/so100.yaml \
    --robot-overrides '~cameras' --arms main_follower
```

**Calibraci√≥n manual del brazo gu√≠a**
Sigue el paso 6 del [v√≠deo de montaje](https://www.youtube.com/watch?v=FioA2oeFZ5I) que ilustra la calibraci√≥n manual. Deber√°s mover el brazo gu√≠a a estas posiciones de forma secuencial:

Ejecuta este script para iniciar la calibraci√≥n manual:

```bash
python lerobot/scripts/control_robot.py calibrate \
    --robot-path lerobot/configs/robot/so100.yaml \
    --robot-overrides '~cameras' --arms main_leader
```

## Teleoperaci√≥n

**Teleoperaci√≥n simple**
¬°Entonces est√°s listo para teleoperar tu robot! Ejecuta este script simple (no se conectar√° ni mostrar√° las c√°maras):

```bash
python lerobot/scripts/control_robot.py teleoperate \
    --robot-path lerobot/configs/robot/so100.yaml \
    --robot-overrides '~cameras' \
    --display-cameras 0
```

<iframe width="900" height="600" src="https://www.youtube.com/embed/hnRwfcyX1ZI?si=RuzYjP_FUTK16lfs" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

## Teleoperaci√≥n con c√°maras de visualizaci√≥n.

Despu√©s de insertar tus dos c√°maras USB, ejecuta el siguiente script para verificar los n√∫meros de puerto de las c√°maras.

```bash
python lerobot/common/robot_devices/cameras/opencv.py \
    --images-dir outputs/images_from_opencv_cameras
```

La terminal imprimir√° la siguiente informaci√≥n.

```markdown
Mac or Windows detected. Finding available camera indices through scanning all indices from 0 to 60
[...]
Camera found at index 2
Camera found at index 4
[...]
Connecting cameras
OpenCVCamera(2, fps=30.0, width=640, height=480, color_mode=rgb)
OpenCVCamera(4, fps=30.0, width=640, height=480, color_mode=rgb)
Saving images to outputs/images_from_opencv_cameras
Frame: 0000 Latency (ms): 39.52
[...]
Frame: 0046 Latency (ms): 40.07
Images have been saved to outputs/images_from_opencv_cameras
```

Puedes encontrar las fotograf√≠as tomadas por cada c√°mara en el directorio `outputs/images_from_opencv_cameras` y confirmar la informaci√≥n del √≠ndice de puerto correspondiente a las c√°maras en diferentes posiciones. Luego completa la alineaci√≥n de los par√°metros de la c√°mara en el archivo `\lerobot\lerobot\configs\robot\so100.yaml`.

<div align="center">
    <img width={800}
    src="https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so100camerayaml.png" />
</div>

Luego podr√°s mostrar las c√°maras en tu computadora mientras est√°s teleoperando, ejecutando el siguiente c√≥digo. Esto es √∫til para preparar tu configuraci√≥n antes de registrar tu primer conjunto de datos.

```bash
python lerobot/scripts/control_robot.py teleoperate \
    --robot-path lerobot/configs/robot/so100.yaml
```

<iframe width="900" height="600" src="https://www.youtube.com/embed/EUcXlLlOjGE?si=6ncQ7o5ZFLR4PGTU" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

## Registrar el conjunto de datos

Una vez que est√©s familiarizado con la teleoperaci√≥n, podr√°s registrar tu primer conjunto de datos con el SO-100.

Si deseas utilizar las funciones del centro Hugging Face para cargar tu conjunto de datos y no lo has hecho anteriormente, aseg√∫rate de haber iniciado sesi√≥n con un token de acceso de escritura, que se puede generar desde la [configuraci√≥n de Hugging Face](https://huggingface.co/settings/tokens):

```bash
huggingface-cli login --token ${HUGGINGFACE_TOKEN} --add-to-git-credential
```

Guarda el nombre de tu repositorio de Hugging Face en una variable para ejecutar estos comandos:

```bash
HF_USER=$(huggingface-cli whoami | head -n 1)
echo $HF_USER
```

Graba 2 episodios y sube tu conjunto de datos al centro:

```bash
python lerobot/scripts/control_robot.py record \
    --robot-path lerobot/configs/robot/so100.yaml \
    --fps 30 \
    --repo-id ${HF_USER}/so100_test \
    --tags so100 tutorial \
    --warmup-time-s 5 \
    --episode-time-s 40 \
    --reset-time-s 10 \
    --num-episodes 2 \
    --push-to-hub 1
    --single-task seeedstudio
```

```markdown
Explicaciones de par√°metros
- wormup-time-s: Se refiere al tiempo de inicializaci√≥n.
- episode-time-s: Representa el tiempo para recopilar datos cada vez.
- reset-time-s: Es el tiempo de preparaci√≥n entre cada recolecci√≥n de datos.
- num-episodes: Indica cu√°ntos grupos de datos se espera recopilar.
- push-to-hub: Determina si se cargan los datos en HuggingFace Hub.
```

<iframe width="900" height="600" src="https://www.youtube.com/embed/wc-qh7UFkuQ?si=-eDB73KgUksyJXa-" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

## Visualizar el conjunto de datos

Si cargaste tu conjunto de datos en el centro con `--push-to-hub 1`, puedes [visualizar tu conjunto de datos en l√≠nea](https://huggingface.co/spaces/lerobot/visualize_dataset) copiando y pegando tu ID de repositorio proporcionada por:

```bash
echo ${HF_USER}/so100_test
```

Si no subiste con `--push-to-hub 0`, tambi√©n puedes visualizarlo localmente con:

```bash
python lerobot/scripts/visualize_dataset_html.py \
  --repo-id ${HF_USER}/so100_test
```

  <div align="center">
      <img width={800}
      src="https://files.seeedstudio.com/wiki/robotics/projects/lerobot/visualize_datasets.png" />
  </div>

## Reproducir una rutina

Ahora intenta reproducir la primer rutina en tu robot:

```bash
python lerobot/scripts/control_robot.py replay \
    --robot-path lerobot/configs/robot/so100.yaml \
    --fps 30 \
    --repo-id ${HF_USER}/so100_test \
    --episode 0
```

## Entrenar una pol√≠tica

Para entrenar una pol√≠tica para controlar tu robot, usa el script `python lerobot/scripts/train.py`. Se requieren algunos argumentos. Aqu√≠ hay un comando de ejemplo:

```bash
python lerobot/scripts/train.py \
  dataset_repo_id=${HF_USER}/so100_test \
  policy=act_so100_real \
  env=so100_real \
  hydra.run.dir=outputs/train/act_so100_test \
  hydra.job.name=act_so100_test \
  device=cuda \
  wandb.enable=false
```

A continuaci√≥n se ofrece una explicaci√≥n detallada:

1. Proporcionamos el conjunto de datos como argumento con `dataset_repo_id=${HF_USER}/so100_test`.
2. Proporcionamos la pol√≠tica con `policy=act_so100_real`. Esto carga configuraciones de [`lerobot/configs/policy/act_so100_real.yaml`](https://github.com/huggingface/lerobot/blob/main/lerobot/configs/policy/act_so100_real.yaml). Es importante destacar que esta pol√≠tica utiliza 2 c√°maras como entrada "computadora port√°til", "tel√©fono".
3. Proporcionamos un entorno como argumento con `env=so100_real`. Esto carga configuraciones de [`lerobot/configs/env/so100_real.yaml`](https://github.com/huggingface/lerobot/blob/main/lerobot/configs/env/so100_real.yaml).
4. Proporcionamos `device=cuda` ya que estamos entrenando en una GPU Nvidia, pero tambi√©n puedes usar `device=mps` si est√°s usando una Mac con Apple Silicon, o `device=cpu` en caso contrario.
5. Proporcionamos `wandb.enable=true` para usar [Pesos y sesgos](https://docs.wandb.ai/quickstart) para visualizar gr√°ficos de entrenamiento. Esto es opcional, pero si lo usas, aseg√∫rate de haber iniciado sesi√≥n ejecutando "wandb login".

El entrenamiento deber√≠a durar varias horas. Encontrar√°s puntos de control en `outputs/train/act_so100_test/checkpoints`.

## Evaluaci√≥n

Puedes usar la funci√≥n `record` desde [`lerobot/scripts/control_robot.py`](https://github.com/huggingface/lerobot/blob/main/lerobot/scripts/control_robot.py) pero con un punto de control de pol√≠tica como entrada. Por ejemplo, ejecuta este comando para registrar 10 episodios de evaluaci√≥n:

```bash
python lerobot/scripts/control_robot.py record \
  --robot-path lerobot/configs/robot/so100.yaml \
  --fps 30 \
  --repo-id ${HF_USER}/eval_act_so100_test \
  --tags so100 tutorial eval \
  --warmup-time-s 5 \
  --episode-time-s 40 \
  --reset-time-s 10 \
  --num-episodes 10 \
  -p outputs/train/act_so100_test/checkpoints/last/pretrained_model
```

Como puedes ver, es casi el mismo comando que se us√≥ anteriormente para registrar tu conjunto de datos de entrenamiento. Dos cosas cambiaron:

1. Hay un argumento `-p` adicional que indica la ruta al punto de control de tu pol√≠tica (por ejemplo, `-p outputs/train/eval_so100_test/checkpoints/last/pretrained_model`). Tambi√©n puedes utilizar el repositorio de modelos si cargaste un punto de control de modelo en el centro (por ejemplo, `-p ${HF_USER}/act_so100_test`).
2. El nombre del conjunto de datos comienza con `eval` para reflejar que est√° ejecutando inferencia (por ejemplo, `--repo-id ${HF_USER}/eval_act_so100_test`).

<iframe width="900" height="600" src="https://www.youtube.com/embed/wc-qh7UFkuQ?si=Y2SXU9T0DSmtz4ll" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

## Referencias

TheRobotStudio Project: [SO-ARM100](https://github.com/TheRobotStudio/SO-ARM100)

Huggingface Project: [Lerobot](https://github.com/huggingface/lerobot/tree/main)

Dnsty: [Jetson Containers](https://github.com/dusty-nv/jetson-containers/tree/master/packages/robots/lerobot)

[Jetson AI Lab](https://www.jetson-ai-lab.com/lerobot.html)

[Diffusion Policy](https://diffusion-policy.cs.columbia.edu/)

[ACT or ALOHA](https://tonyzhaozh.github.io/aloha/)

[TDMPC](https://www.nicklashansen.com/td-mpc/)

[VQ-BeT](https://sjlee.cc/vq-bet/)

## Soporte Tech y discusi√≥n del producto

¬°Gracias por elegir nuestros productos! Estamos aqu√≠ para darte soporte y asegurar que tu experiencia con nuestros productos sea la mejor posible. Tenemos diversos canales de comunicaci√≥n para adaptarnos distintas preferencias y necesidades.

<div class="button_tech_support_container">
<a href="https://forum.seeedstudio.com/" class="button_forum"></a>
<a href="https://www.seeedstudio.com/contacts" class="button_email"></a>
</div>

<div class="button_tech_support_container">
<a href="https://discord.gg/eWkprNDMU7" class="button_discord"></a>
<a href="https://github.com/Seeed-Studio/wiki-documents/discussions/69" class="button_discussion"></a>
</div>
